{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb0769e4-65bf-4232-9834-a6a2d523107f",
   "metadata": {},
   "source": [
    "# Create the size estimation csv if not exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536e720b-c6b0-4b9d-a6b1-e1550528cd30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_index</th>\n",
       "      <th>tx_index</th>\n",
       "      <th>method</th>\n",
       "      <th>est_size</th>\n",
       "      <th>est_center</th>\n",
       "      <th>true_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Density-weighted centers (on KMeans partitions)</td>\n",
       "      <td>3489</td>\n",
       "      <td>[3.675564212004624, 1.0209360816840582, -1.653...</td>\n",
       "      <td>3701.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GMM means</td>\n",
       "      <td>2201</td>\n",
       "      <td>[3.9690072500659626, 1.1814134845627842, -1.75...</td>\n",
       "      <td>3701.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>KMeans centers</td>\n",
       "      <td>3489</td>\n",
       "      <td>[3.2141649909603878, 0.834196541087591, -1.757...</td>\n",
       "      <td>3701.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MCD-inlier density-weighted centers (on KMeans...</td>\n",
       "      <td>3489</td>\n",
       "      <td>[3.964486847638297, 1.2195497596063765, -1.593...</td>\n",
       "      <td>3701.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mean Shift centers (MeanShift bandwidth=1.79, ...</td>\n",
       "      <td>2854</td>\n",
       "      <td>[4.469802735985509, 0.997070926347141, -1.5710...</td>\n",
       "      <td>3701.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119995</th>\n",
       "      <td>9999</td>\n",
       "      <td>1</td>\n",
       "      <td>GMM means</td>\n",
       "      <td>3784</td>\n",
       "      <td>[-0.005330030300972829, 0.598339170900159, -1....</td>\n",
       "      <td>1609.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>9999</td>\n",
       "      <td>1</td>\n",
       "      <td>KMeans centers</td>\n",
       "      <td>1805</td>\n",
       "      <td>[2.765690554348608, 1.3953316396413447, -0.445...</td>\n",
       "      <td>1609.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>9999</td>\n",
       "      <td>1</td>\n",
       "      <td>MCD-inlier density-weighted centers (on KMeans...</td>\n",
       "      <td>1805</td>\n",
       "      <td>[3.2817243241126914, 1.8729069963852762, -1.08...</td>\n",
       "      <td>1609.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>9999</td>\n",
       "      <td>1</td>\n",
       "      <td>Mean Shift centers (MeanShift bandwidth=1.6, k...</td>\n",
       "      <td>395</td>\n",
       "      <td>[1.888018349244157, 2.8038930841001792, -3.503...</td>\n",
       "      <td>1609.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>9999</td>\n",
       "      <td>1</td>\n",
       "      <td>Robust (MinCovDet) centers (on KMeans partitions)</td>\n",
       "      <td>1805</td>\n",
       "      <td>[3.2757498561118403, 1.8003836699854403, -1.18...</td>\n",
       "      <td>1609.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        file_index  tx_index  \\\n",
       "0                0         0   \n",
       "1                0         0   \n",
       "2                0         0   \n",
       "3                0         0   \n",
       "4                0         0   \n",
       "...            ...       ...   \n",
       "119995        9999         1   \n",
       "119996        9999         1   \n",
       "119997        9999         1   \n",
       "119998        9999         1   \n",
       "119999        9999         1   \n",
       "\n",
       "                                                   method  est_size  \\\n",
       "0         Density-weighted centers (on KMeans partitions)      3489   \n",
       "1                                               GMM means      2201   \n",
       "2                                          KMeans centers      3489   \n",
       "3       MCD-inlier density-weighted centers (on KMeans...      3489   \n",
       "4       Mean Shift centers (MeanShift bandwidth=1.79, ...      2854   \n",
       "...                                                   ...       ...   \n",
       "119995                                          GMM means      3784   \n",
       "119996                                     KMeans centers      1805   \n",
       "119997  MCD-inlier density-weighted centers (on KMeans...      1805   \n",
       "119998  Mean Shift centers (MeanShift bandwidth=1.6, k...       395   \n",
       "119999  Robust (MinCovDet) centers (on KMeans partitions)      1805   \n",
       "\n",
       "                                               est_center  true_size  \n",
       "0       [3.675564212004624, 1.0209360816840582, -1.653...     3701.0  \n",
       "1       [3.9690072500659626, 1.1814134845627842, -1.75...     3701.0  \n",
       "2       [3.2141649909603878, 0.834196541087591, -1.757...     3701.0  \n",
       "3       [3.964486847638297, 1.2195497596063765, -1.593...     3701.0  \n",
       "4       [4.469802735985509, 0.997070926347141, -1.5710...     3701.0  \n",
       "...                                                   ...        ...  \n",
       "119995  [-0.005330030300972829, 0.598339170900159, -1....     1609.0  \n",
       "119996  [2.765690554348608, 1.3953316396413447, -0.445...     1609.0  \n",
       "119997  [3.2817243241126914, 1.8729069963852762, -1.08...     1609.0  \n",
       "119998  [1.888018349244157, 2.8038930841001792, -3.503...     1609.0  \n",
       "119999  [3.2757498561118403, 1.8003836699854403, -1.18...     1609.0  \n",
       "\n",
       "[120000 rows x 6 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def to_list(s):\n",
    "    \"\"\"Parse Python-literal lists stored as strings; pass through lists unchanged.\"\"\"\n",
    "    if isinstance(s, list):\n",
    "        return s\n",
    "    if pd.isna(s):\n",
    "        return []\n",
    "    return ast.literal_eval(str(s))\n",
    "\n",
    "def build_long_rows(row):\n",
    "    \"\"\"\n",
    "    From one wide row produce per-cluster rows:\n",
    "      file_index  -> number from 'file' (e.g., '0.csv' -> 0)\n",
    "      tx_index    -> matched *true* index (c)\n",
    "      method      -> passthrough\n",
    "      est_size    -> cluster_sizes[r]\n",
    "      est_center  -> centers_est[r]\n",
    "      true_size   -> true_cluster_sizes[c]  (or true_cluster_sizes_matched[r], equivalent)\n",
    "    \"\"\"\n",
    "    file_name = str(row[\"file\"])\n",
    "    # extract number before \".csv\", fallback to original if not numeric\n",
    "    base = os.path.splitext(os.path.basename(file_name))[0]\n",
    "    try:\n",
    "        file_index = int(base)\n",
    "    except ValueError:\n",
    "        file_index = base\n",
    "\n",
    "    method = row[\"method\"]\n",
    "\n",
    "    # parse arrays\n",
    "    cluster_sizes                = to_list(row.get(\"cluster_sizes\", []))\n",
    "    true_cluster_sizes           = to_list(row.get(\"true_cluster_sizes\", []))\n",
    "    true_cluster_sizes_matched   = to_list(row.get(\"true_cluster_sizes_matched\", []))\n",
    "    centers_est                  = to_list(row.get(\"centers_est\", []))\n",
    "    match_row_ind               = to_list(row.get(\"match_row_ind\", []))\n",
    "    match_col_ind               = to_list(row.get(\"match_col_ind\", []))\n",
    "\n",
    "    # prefer explicit pairing (r -> c) via match indices\n",
    "    use_matched_vector = len(true_cluster_sizes_matched) == len(cluster_sizes) and len(cluster_sizes) > 0\n",
    "\n",
    "    out = []\n",
    "    # If we have Hungarian pairing, zip (r, c). Otherwise, assume identity mapping.\n",
    "    pairs = list(zip(match_row_ind, match_col_ind)) if match_row_ind and match_col_ind else [(i, i) for i in range(len(cluster_sizes))]\n",
    "\n",
    "    for r, c in pairs:\n",
    "        # guard against out-of-range indices\n",
    "        if r is None or c is None: \n",
    "            continue\n",
    "        if r < 0 or r >= len(cluster_sizes): \n",
    "            continue\n",
    "        # est fields\n",
    "        est_size   = int(cluster_sizes[r]) if pd.notna(cluster_sizes[r]) else None\n",
    "        est_center = centers_est[r] if r < len(centers_est) else None\n",
    "\n",
    "        # true size: either via matched array at r, or via c into true_cluster_sizes\n",
    "        if use_matched_vector:\n",
    "            true_size = int(true_cluster_sizes_matched[r])\n",
    "        else:\n",
    "            if c < 0 or c >= len(true_cluster_sizes):\n",
    "                true_size = None\n",
    "            else:\n",
    "                true_size = int(true_cluster_sizes[c])\n",
    "\n",
    "        # tx_index is the *true* index (c) that r matched to\n",
    "        tx_index = int(c)\n",
    "\n",
    "        out.append({\n",
    "            \"file_index\": file_index,\n",
    "            \"tx_index\": tx_index,\n",
    "            \"method\": method,\n",
    "            \"est_size\": est_size,\n",
    "            \"est_center\": est_center,\n",
    "            \"true_size\": true_size,\n",
    "        })\n",
    "    return out\n",
    "\n",
    "def convert_wide_to_long(in_csv: str, out_csv: str):\n",
    "    df = pd.read_csv(in_csv)\n",
    "\n",
    "    rows = []\n",
    "    for _, r in df.iterrows():\n",
    "        rows.extend(build_long_rows(r))\n",
    "    out = pd.DataFrame(\n",
    "        rows,\n",
    "        columns=[\"file_index\",\"tx_index\",\"method\",\"est_size\",\"est_center\",\"true_size\"]\n",
    "    )\n",
    "\n",
    "    # --- remove duplicates where file_index, tx_index, method are the same ---\n",
    "    before = len(out)\n",
    "    out = out.drop_duplicates(subset=[\"file_index\",\"tx_index\",\"method\"], keep=\"first\")\n",
    "    after = len(out)\n",
    "    if after < before:\n",
    "        print(f\"[info] dropped {before-after} duplicate rows with same (file_index, tx_index, method)\")\n",
    "\n",
    "    # --- fill NaN true_size from KMeans centers per (file_index, tx_index) ---\n",
    "    # Make sure true_size is numeric so NaNs are recognized\n",
    "    out[\"true_size\"] = pd.to_numeric(out[\"true_size\"], errors=\"coerce\")\n",
    "\n",
    "    # Lookup table: KMeans centers -> true_size_km\n",
    "    km = (\n",
    "        out[out[\"method\"] == \"KMeans centers\"]\n",
    "        .loc[:, [\"file_index\", \"tx_index\", \"true_size\"]]\n",
    "        .rename(columns={\"true_size\": \"true_size_km\"})\n",
    "    )\n",
    "\n",
    "    # Merge and fill\n",
    "    out = out.merge(km, on=[\"file_index\", \"tx_index\"], how=\"left\")\n",
    "    # Only fill where current true_size is NaN; leave KMeans row itself unchanged even if NaN\n",
    "    mask_needs_fill = out[\"true_size\"].isna() & out[\"true_size_km\"].notna()\n",
    "    out.loc[mask_needs_fill, \"true_size\"] = out.loc[mask_needs_fill, \"true_size_km\"]\n",
    "    out = out.drop(columns=[\"true_size_km\"])\n",
    "\n",
    "    out.sort_values(by=[\"file_index\",\"tx_index\",\"method\"], inplace=True, ignore_index=True)\n",
    "    out.to_csv(out_csv, index=False)\n",
    "    return out\n",
    "\n",
    "convert_wide_to_long(\"./uniform_test/angle_results/all_results_enhanced.csv\", \"size_estimation_2Tx.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada79991-ff63-4f89-88b6-d28c36134ecd",
   "metadata": {},
   "source": [
    "# Angle Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cbfa9f-994c-4ac1-bfef-162984051229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected K = 2 clusters per scene.\n",
      "Built 10000 training rows with K=2.\n",
      "Saved train/test split info to train_test_split.csv\n",
      "Epoch   0 | Train 1.002237 | Val 0.797174\n",
      "Epoch  50 | Train 0.018982 | Val 0.015255\n",
      "Epoch 100 | Train 0.011579 | Val 0.009071\n",
      "Epoch 150 | Train 0.008223 | Val 0.006113\n",
      "Epoch 200 | Train 0.006209 | Val 0.004411\n",
      "Epoch 250 | Train 0.005184 | Val 0.003751\n",
      "Epoch 300 | Train 0.004507 | Val 0.003470\n",
      "Epoch 350 | Train 0.004138 | Val 0.003153\n",
      "Epoch 400 | Train 0.003594 | Val 0.003005\n",
      "Epoch 450 | Train 0.003401 | Val 0.002910\n",
      "Epoch 500 | Train 0.003136 | Val 0.002783\n",
      "Epoch 550 | Train 0.002923 | Val 0.002700\n",
      "Epoch 600 | Train 0.002861 | Val 0.002688\n",
      "Epoch 650 | Train 0.002692 | Val 0.002791\n",
      "Epoch 700 | Train 0.002468 | Val 0.002584\n",
      "Epoch 750 | Train 0.002404 | Val 0.002558\n",
      "Epoch 800 | Train 0.002325 | Val 0.002510\n",
      "Epoch 850 | Train 0.002223 | Val 0.002497\n",
      "Epoch 900 | Train 0.002350 | Val 0.002728\n",
      "Epoch 950 | Train 0.002156 | Val 0.002612\n",
      "\n",
      "=== Angle Error Results (degrees) ===\n",
      "TX0 — RAW mean: 7.079, ANN mean: 1.936\n",
      "TX1 — RAW mean: 6.997, ANN mean: 1.927\n",
      "Overall RAW: 7.038, ANN: 1.932\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ============================================================\n",
    "# Helpers\n",
    "\n",
    "def to_length(v, L=5.0, eps=1e-12):\n",
    "    v = np.asarray(v, dtype=float)\n",
    "    n = np.linalg.norm(v)\n",
    "    if n < eps:\n",
    "        return v.tolist()  # leave zero vector as-is\n",
    "    return (v * (L / n)).tolist()\n",
    "\n",
    "def to_vec3(x):\n",
    "    if isinstance(x, list): return [float(x[0]), float(x[1]), float(x[2])]\n",
    "    if isinstance(x, str):  return list(map(float, ast.literal_eval(x)))\n",
    "    raise ValueError(\"Unexpected type for 3D vector\")\n",
    "\n",
    "def angle_error_deg(pred, true):\n",
    "    \"\"\"Mean angle error in degrees between two sets of 3D vectors\"\"\"\n",
    "    pred = np.asarray(pred, dtype=float)\n",
    "    true = np.asarray(true, dtype=float)\n",
    "    pred /= np.linalg.norm(pred, axis=1, keepdims=True) + 1e-12\n",
    "    true /= np.linalg.norm(true, axis=1, keepdims=True) + 1e-12\n",
    "    cos = np.clip(np.sum(pred*true, axis=1), -1.0, 1.0)\n",
    "    return np.degrees(np.arccos(cos))\n",
    "\n",
    "# ============================================================\n",
    "# Load estimated data\n",
    "df = pd.read_csv(\"size_estimation_2Tx.csv\")\n",
    "df = df[df[\"method\"] == \"KMeans centers\"].copy()\n",
    "# df = df[df[\"method\"] == \"MCD-inlier density-weighted centers (on KMeans partitions)\"].copy()\n",
    "\n",
    "\n",
    "df[\"est_center\"] = df[\"est_center\"].apply(to_vec3)\n",
    "df[\"est_size\"]   = df[\"est_size\"].astype(float)\n",
    "df[\"tx_index\"]   = df[\"tx_index\"].astype(int)\n",
    "\n",
    "# Load config truth\n",
    "cfg = pd.read_csv(\"dataset/config.csv\")\n",
    "if \"file_index\" not in cfg.columns:\n",
    "    cfg = cfg.reset_index().rename(columns={\"index\":\"file_index\"})\n",
    "\n",
    "truth_map = {}\n",
    "for _, r in cfg.iterrows():\n",
    "    centers = r[\"tx_centers\"]\n",
    "    centers = ast.literal_eval(centers) if isinstance(centers, str) else centers\n",
    "    centers = [list(map(float, c)) for c in centers]\n",
    "    # scale each ground-truth center to have length 5.0\n",
    "    centers = [to_length(c, 5.0) for c in centers]\n",
    "    truth_map[int(r[\"file_index\"])] = centers\n",
    "\n",
    "# Keep only scenes present in truth\n",
    "df = df[df[\"file_index\"].isin(truth_map.keys())]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Infer K from ground-truth config and build generalized dataset\n",
    "# ------------------------------------------------------------\n",
    "K = None\n",
    "for fid, centers in truth_map.items():\n",
    "    if K is None:\n",
    "        K = len(centers)\n",
    "    else:\n",
    "        assert K == len(centers), f\"Inconsistent K across files (file {fid}).\"\n",
    "print(f\"Detected K = {K} clusters per scene.\")\n",
    "\n",
    "# Keep only scenes that have all K tx_index present (for the chosen method)\n",
    "def has_all_k(s):\n",
    "    return set(s[\"tx_index\"].unique()) == set(range(K))\n",
    "\n",
    "g = (df.groupby(\"file_index\", as_index=False)\n",
    "       .filter(has_all_k)\n",
    "       .sort_values([\"file_index\", \"tx_index\"]))\n",
    "\n",
    "# Build rows with K clusters per scene\n",
    "rows = []\n",
    "for fid, s in g.groupby(\"file_index\"):\n",
    "    s = s.sort_values(\"tx_index\")\n",
    "    if list(s[\"tx_index\"]) != list(range(K)):\n",
    "        continue  # safety\n",
    "\n",
    "    # Estimated features: [size_k, est_center_k (3)] for k in 0..K-1\n",
    "    feat = []\n",
    "    for k in range(K):\n",
    "        feat.append(float(s.loc[s[\"tx_index\"] == k, \"est_size\"].values[0]))\n",
    "        feat.extend(list(map(float, s.loc[s[\"tx_index\"] == k, \"est_center\"].values[0])))\n",
    "\n",
    "    # True centers (each already scaled to length 5.0 above)\n",
    "    tcenters = truth_map[int(fid)]\n",
    "    target = []\n",
    "    for k in range(K):\n",
    "        target.extend(list(map(float, tcenters[k])))\n",
    "\n",
    "    rows.append({\"file_index\": int(fid), \"X\": feat, \"y\": target})\n",
    "\n",
    "pairs = pd.DataFrame(rows)\n",
    "print(f\"Built {len(pairs)} training rows with K={K}.\")\n",
    "\n",
    "# ============================================================\n",
    "# Features (input) & Targets (true centers, 3K)\n",
    "X = np.array(pairs[\"X\"].to_list(), dtype=float)      # (N, 4*K)\n",
    "y = np.array(pairs[\"y\"].to_list(), dtype=float)      # (N, 3*K)\n",
    "\n",
    "# ============================================================\n",
    "indices = np.arange(len(pairs))\n",
    "\n",
    "# First split: 70% train, 30% temp (for val + test)\n",
    "X_train, X_temp, y_train, y_temp, idx_train, idx_temp = train_test_split(\n",
    "    X, y, indices, test_size=0.30, random_state=42\n",
    ")\n",
    "\n",
    "# Second split: 50% of temp -> 15% val, 15% test\n",
    "X_val, X_test, y_val, y_test, idx_val, idx_test = train_test_split(\n",
    "    X_temp, y_temp, idx_temp, test_size=0.50, random_state=42\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# Save train/val/test split into CSV\n",
    "# ============================================================\n",
    "train_idx = pairs.iloc[idx_train][\"file_index\"].reset_index(drop=True)\n",
    "val_idx   = pairs.iloc[idx_val][\"file_index\"].reset_index(drop=True)\n",
    "test_idx  = pairs.iloc[idx_test][\"file_index\"].reset_index(drop=True)\n",
    "\n",
    "split_df = pd.DataFrame({\n",
    "    \"file_index\": pd.concat([train_idx, val_idx, test_idx], ignore_index=True),\n",
    "    \"split\":     [\"train\"] * len(train_idx) + \\\n",
    "                 [\"validation\"] * len(val_idx) + \\\n",
    "                 [\"test\"] * len(test_idx)\n",
    "})\n",
    "\n",
    "split_df.to_csv(\"train_val_test_split_2Tx.csv\", index=False)\n",
    "print(\"Saved train/val/test split info to train_val_test_split_2Tx.csv\")\n",
    "\n",
    "# Scale inputs & outputs\n",
    "scaler_X = StandardScaler()\n",
    "X_train_s = scaler_X.fit_transform(X_train)\n",
    "X_val_s   = scaler_X.transform(X_val) \n",
    "X_test_s  = scaler_X.transform(X_test)\n",
    "\n",
    "y_mean = y_train.mean(axis=0)\n",
    "y_std  = y_train.std(axis=0); y_std[y_std==0] = 1.0\n",
    "y_train_s = (y_train - y_mean) / y_std\n",
    "y_val_s   = (y_val - y_mean) / y_std \n",
    "y_test_s  = (y_test - y_mean) / y_std\n",
    "\n",
    "Xtr = torch.tensor(X_train_s, dtype=torch.float32)\n",
    "ytr = torch.tensor(y_train_s, dtype=torch.float32)\n",
    "Xva = torch.tensor(X_val_s,   dtype=torch.float32) \n",
    "yva = torch.tensor(y_val_s,   dtype=torch.float32) \n",
    "Xte = torch.tensor(X_test_s,  dtype=torch.float32)\n",
    "yte = torch.tensor(y_test_s,  dtype=torch.float32)\n",
    "\n",
    "# ============================================================\n",
    "# Random-permutation augmentation helper (generalizes random swap)\n",
    "def random_permute_batch(X, y, K, p=0.5):\n",
    "    \"\"\"\n",
    "    X: (B, 4*K) -> blocks of 4 per cluster [size, cx, cy, cz]\n",
    "    y: (B, 3*K) -> blocks of 3 per cluster [tx, ty, tz]\n",
    "    With probability p per sample, apply a random permutation of the K clusters\n",
    "    to both X and y consistently.\n",
    "    \"\"\"\n",
    "    B = X.size(0)\n",
    "    device = X.device\n",
    "\n",
    "    Xb = X.view(B, K, 4).clone()\n",
    "    yb = y.view(B, K, 3).clone()\n",
    "\n",
    "    mask = (torch.rand(B, device=device) < p)\n",
    "    idxs = torch.arange(B, device=device)[mask]\n",
    "\n",
    "    for i in idxs.tolist():\n",
    "        perm = torch.randperm(K, device=device)\n",
    "        Xb[i] = Xb[i][perm]\n",
    "        yb[i] = yb[i][perm]\n",
    "\n",
    "    return Xb.view(B, 4*K), yb.view(B, 3*K)\n",
    "\n",
    "# ============================================================\n",
    "# Residual MLP (dynamic I/O sizes)\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, dim, p_drop=0.1):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(dim, dim)\n",
    "        self.fc2 = nn.Linear(dim, dim)\n",
    "        self.act = nn.ReLU()\n",
    "        self.drop = nn.Dropout(p_drop)\n",
    "    def forward(self, x):\n",
    "        h = self.act(self.fc1(x))\n",
    "        h = self.drop(self.fc2(h))\n",
    "        return x + h\n",
    "\n",
    "class ResidualMLP(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, hidden_dim=256, depth=6, p_drop=0.1):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Sequential(nn.Linear(in_dim, hidden_dim), nn.ReLU())\n",
    "        self.blocks = nn.Sequential(*[ResidualBlock(hidden_dim, p_drop) for _ in range(depth)])\n",
    "        self.head = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 128), nn.ReLU(),\n",
    "            nn.Linear(128, out_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.blocks(x)\n",
    "        return self.head(x)\n",
    "\n",
    "in_dim = 4 * K   # per cluster: [size, cx, cy, cz]\n",
    "out_dim = 3 * K  # per cluster: [tx, ty, tz]\n",
    "\n",
    "model = ResidualMLP(in_dim=in_dim, out_dim=out_dim)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# ============================================================\n",
    "# Training loop (uses random permutation augmentation)\n",
    "best_val = float(\"inf\")\n",
    "best_state = None\n",
    "EPOCHS = 1000\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "\n",
    "    # --- random permutation augmentation applied each epoch ---\n",
    "    Xb, yb = random_permute_batch(Xtr, ytr, K=K, p=0.5)\n",
    "\n",
    "    pred = model(Xb)\n",
    "    loss = loss_fn(pred, yb)\n",
    "    opt.zero_grad(); loss.backward(); opt.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # --- Use validation set for early stopping ---\n",
    "        val_loss = loss_fn(model(Xva), yva).item()\n",
    "\n",
    "    if val_loss < best_val:\n",
    "        best_val = val_loss\n",
    "        best_state = {k: v.detach().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"Epoch {epoch:3d} | Train {loss.item():.6f} | Val {val_loss:.6f}\")\n",
    "\n",
    "# Restore best model based on validation performance\n",
    "if best_state:\n",
    "    model.load_state_dict(best_state)\n",
    "\n",
    "# ============================================================\n",
    "# Predict & unscale\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_s = model(Xte).cpu().numpy()\n",
    "\n",
    "y_pred = y_pred_s * y_std + y_mean   # (N, 3*K)\n",
    "\n",
    "# ============================================================\n",
    "# Generalized Angle error evaluation (for arbitrary K)\n",
    "# Extract estimated centers from raw X_test (unscaled), blocks of 4: [size, cx, cy, cz]\n",
    "est_blocks = [X_test[:, 1 + 4*k : 1 + 4*k + 3] for k in range(K)]  # each (N,3)\n",
    "\n",
    "errs_raw = []\n",
    "errs_ann = []\n",
    "for k in range(K):\n",
    "    y_true_k = y_test[:, 3*k : 3*k + 3]\n",
    "    y_pred_k = y_pred[:, 3*k : 3*k + 3]\n",
    "    est_k    = est_blocks[k]\n",
    "\n",
    "    err_raw_k = angle_error_deg(est_k, y_true_k)\n",
    "    err_ann_k = angle_error_deg(y_pred_k, y_true_k)\n",
    "\n",
    "    errs_raw.append(err_raw_k)\n",
    "    errs_ann.append(err_ann_k)\n",
    "\n",
    "print(\"\\n=== Angle Error Results (degrees) ===\")\n",
    "for k in range(K):\n",
    "    print(f\"TX{k} — RAW mean: {errs_raw[k].mean():.3f}, ANN mean: {errs_ann[k].mean():.3f}\")\n",
    "print(f\"Overall RAW: {np.hstack(errs_raw).mean():.3f}, ANN: {np.hstack(errs_ann).mean():.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f0dde6-5f0b-42ff-aa58-fb8426327498",
   "metadata": {},
   "source": [
    "# Size Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d89e2e6-e861-4c15-b475-1c5f691c77dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected K = 2 clusters per scene (using modal count).\n",
      "Built 10000 training rows with K=2.\n",
      "Reused split — train N=8000, test N=2000\n",
      "Epoch   0 | Train 0.059491 | Val 0.028121 | LR 1.00e-03\n",
      "Epoch  50 | Train 0.012742 | Val 0.013658 | LR 1.00e-03\n",
      "Epoch 100 | Train 0.005164 | Val 0.011712 | LR 5.00e-04\n",
      "Epoch 150 | Train 0.001844 | Val 0.011705 | LR 1.25e-04\n",
      "Early stopping at epoch 166\n",
      "RMSE TX0 — ANN: 359.3345   RAW: 670.7736   Δ=311.4391\n",
      "RMSE TX1 — ANN: 354.7402   RAW: 670.7736   Δ=316.0334\n",
      "RMSE Overall — ANN: 357.0448   RAW: 670.7736   Δ=313.7289\n",
      "Best Val Loss (scaled SmoothL1): 0.010441\n",
      "MAPE TX0 — ANN: 3.60%\n",
      "MAPE TX1 — ANN: 3.73%\n",
      "MAPE Overall — ANN: 3.66%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# ------------------------------- Load & filter -------------------------------\n",
    "df = pd.read_csv(\"size_estimation_2Tx.csv\")\n",
    "df = df[df[\"method\"] == \"KMeans centers\"].copy()\n",
    "#df = df[df[\"method\"] == \"MCD-inlier density-weighted centers (on KMeans partitions)\"].copy()\n",
    "\n",
    "def to_vec3(x):\n",
    "    if isinstance(x, list): return [float(x[0]), float(x[1]), float(x[2])]\n",
    "    if isinstance(x, str):  return list(map(float, ast.literal_eval(x)))\n",
    "    raise ValueError(\"Unexpected est_center type\")\n",
    "\n",
    "df[\"est_center\"] = df[\"est_center\"].apply(to_vec3)\n",
    "df[\"est_size\"]   = df[\"est_size\"].astype(float)\n",
    "df[\"true_size\"]  = df[\"true_size\"].astype(float)\n",
    "df[\"tx_index\"]   = df[\"tx_index\"].astype(int)\n",
    "\n",
    "# ------------------------------- Infer K and build multi-cluster rows -------------------------------\n",
    "counts_per_file = df.groupby(\"file_index\")[\"tx_index\"].nunique()\n",
    "K = int(counts_per_file.mode().iloc[0])\n",
    "print(f\"Detected K = {K} clusters per scene (using modal count).\")\n",
    "\n",
    "def has_all_k(s):\n",
    "    return set(s[\"tx_index\"].unique()) == set(range(K))\n",
    "\n",
    "g = (df.groupby([\"file_index\"], as_index=False)\n",
    "       .filter(has_all_k)\n",
    "       .sort_values([\"file_index\", \"tx_index\"])\n",
    "       .reset_index(drop=True))\n",
    "\n",
    "rows = []\n",
    "for fid, s in g.groupby(\"file_index\"):\n",
    "    s = s.sort_values(\"tx_index\")\n",
    "    if list(s[\"tx_index\"]) != list(range(K)):\n",
    "        continue\n",
    "    feat = []\n",
    "    target = []\n",
    "    for k in range(K):\n",
    "        feat.append(float(s.loc[s[\"tx_index\"] == k, \"est_size\"].values[0]))\n",
    "        feat.extend(list(map(float, s.loc[s[\"tx_index\"] == k, \"est_center\"].values[0])))\n",
    "        target.append(float(s.loc[s[\"tx_index\"] == k, \"true_size\"].values[0]))\n",
    "    rows.append({\"file_index\": int(fid), \"X\": feat, \"y\": target})\n",
    "\n",
    "pairs = pd.DataFrame(rows)\n",
    "print(f\"Built {len(pairs)} training rows with K={K}.\")\n",
    "\n",
    "X_all = np.array(pairs[\"X\"].to_list(), dtype=float)      # (N, 4*K)\n",
    "y_all = np.array(pairs[\"y\"].to_list(), dtype=float)      # (N, K)\n",
    "\n",
    "# ------------------------------- Load consistent split -------------------------------\n",
    "SPLIT_CSV = \"train_val_test_split_2Tx.csv\"   # produced by first script\n",
    "split_df = pd.read_csv(SPLIT_CSV)\n",
    "train_files = set(split_df.loc[split_df[\"split\"] == \"train\", \"file_index\"].astype(int))\n",
    "val_files   = set(split_df.loc[split_df[\"split\"] == \"validation\", \"file_index\"].astype(int))\n",
    "test_files  = set(split_df.loc[split_df[\"split\"] == \"test\",  \"file_index\"].astype(int))\n",
    "\n",
    "pairs[\"file_index\"] = pairs[\"file_index\"].astype(int)\n",
    "pairs_train = pairs[pairs[\"file_index\"].isin(train_files)].copy()\n",
    "pairs_val   = pairs[pairs[\"file_index\"].isin(val_files)].copy()\n",
    "pairs_test  = pairs[pairs[\"file_index\"].isin(test_files)].copy()\n",
    "\n",
    "X_train = np.array(pairs_train[\"X\"].to_list(), dtype=float)\n",
    "y_train = np.array(pairs_train[\"y\"].to_list(), dtype=float)\n",
    "X_val   = np.array(pairs_val[\"X\"].to_list(), dtype=float)\n",
    "y_val   = np.array(pairs_val[\"y\"].to_list(), dtype=float)\n",
    "X_test  = np.array(pairs_test[\"X\"].to_list(),  dtype=float)\n",
    "y_test  = np.array(pairs_test[\"y\"].to_list(),  dtype=float)\n",
    "print(f\"Reused split — train N={len(X_train)}, val N={len(X_val)}, test N={len(X_test)}\")\n",
    "\n",
    "# ------------------------------- Scaling -------------------------------\n",
    "scaler_X_size = StandardScaler()\n",
    "X_train_s = scaler_X_size.fit_transform(X_train)\n",
    "X_val_s   = scaler_X_size.transform(X_val) \n",
    "X_test_s  = scaler_X_size.transform(X_test)\n",
    "\n",
    "y_mean_size = y_train.mean(axis=0)\n",
    "y_std_size  = y_train.std(axis=0); y_std_size[y_std_size==0] = 1.0\n",
    "y_train_s = (y_train - y_mean_size) / y_std_size\n",
    "y_val_s   = (y_val - y_mean_size) / y_std_size\n",
    "y_test_s  = (y_test  - y_mean_size) / y_std_size\n",
    "\n",
    "# ------------------------------- Dataset -------------------------------\n",
    "class MultiKDataset(Dataset):\n",
    "    def __init__(self, Xs, ys, K, permute_prob=0.5, train=True):\n",
    "        self.Xs = np.ascontiguousarray(Xs, dtype=np.float32)\n",
    "        self.ys = np.ascontiguousarray(ys, dtype=np.float32)\n",
    "        self.K = int(K)\n",
    "        self.permute_prob = float(permute_prob)\n",
    "        self.train = bool(train)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.Xs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.Xs[idx].copy()\n",
    "        y = self.ys[idx].copy()\n",
    "        if self.train and np.random.rand() < self.permute_prob:\n",
    "            perm = np.random.permutation(self.K)\n",
    "            x = x.reshape(self.K, 4)[perm].reshape(-1)\n",
    "            y = y[perm]\n",
    "        return torch.from_numpy(x), torch.from_numpy(y)\n",
    "\n",
    "train_ds = MultiKDataset(X_train_s, y_train_s, K=K, permute_prob=0.5, train=True)\n",
    "val_ds   = MultiKDataset(X_val_s,   y_val_s,   K=K, permute_prob=0.0, train=False)\n",
    "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=256, shuffle=False)\n",
    "\n",
    "# ------------------------------- Residual MLP -------------------------------\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, dim, p_drop=0.1, use_bn=False):\n",
    "        super().__init__()\n",
    "        layers = [nn.Linear(dim, dim), nn.ReLU()]\n",
    "        if use_bn:\n",
    "            layers.append(nn.BatchNorm1d(dim))\n",
    "        layers += [nn.Linear(dim, dim)]\n",
    "        self.net = nn.Sequential(*layers)\n",
    "        self.dropout = nn.Dropout(p_drop) if p_drop > 0 else nn.Identity()\n",
    "    def forward(self, x):\n",
    "        return x + self.dropout(self.net(x))\n",
    "\n",
    "class ResidualMLP(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, hidden_dim=256, depth=6, p_drop=0.1, use_bn=False):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Sequential(nn.Linear(in_dim, hidden_dim), nn.ReLU())\n",
    "        self.blocks = nn.Sequential(*[ResidualBlock(hidden_dim, p_drop=p_drop, use_bn=use_bn) for _ in range(depth)])\n",
    "        self.head = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, out_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.head(self.blocks(self.stem(x)))\n",
    "\n",
    "in_dim = 4 * K\n",
    "out_dim = K\n",
    "size = ResidualMLP(in_dim=in_dim, out_dim=out_dim, hidden_dim=256, depth=6, p_drop=0.1)\n",
    "\n",
    "# ------------------------------- Optim & training -------------------------------\n",
    "opt = torch.optim.Adam(size.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "loss_fn = nn.SmoothL1Loss(beta=1.0)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, factor=0.5, patience=20)\n",
    "\n",
    "best_val, best_state, bad, patience = float(\"inf\"), None, 0, 60\n",
    "EPOCHS = 1000\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    size.train(); running = 0.0\n",
    "    for xb, yb in train_loader:\n",
    "        pred = size(xb)\n",
    "        loss = loss_fn(pred, yb)\n",
    "        opt.zero_grad(); loss.backward(); opt.step()\n",
    "        running += loss.item() * xb.size(0)\n",
    "    train_loss = running / len(train_ds)\n",
    "\n",
    "    size.eval(); val_running = 0.0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            pred = size(xb)\n",
    "            val_running += loss_fn(pred, yb).item() * xb.size(0)\n",
    "    val_loss = val_running / len(val_ds)\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    train_losses.append(train_loss); val_losses.append(val_loss)\n",
    "    if val_loss < best_val - 1e-6:\n",
    "        best_val, bad = val_loss, 0\n",
    "        best_state = {k: v.detach().cpu().clone() for k, v in size.state_dict().items()}\n",
    "    else:\n",
    "        bad += 1\n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"Epoch {epoch:3d} | Train {train_loss:.6f} | Val {val_loss:.6f} | LR {opt.param_groups[0]['lr']:.2e}\")\n",
    "    if bad >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch}\"); break\n",
    "\n",
    "if best_state is not None:\n",
    "    size.load_state_dict(best_state)\n",
    "\n",
    "# ------------------------------- Predict & evaluate -------------------------------\n",
    "size.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_s = size(torch.from_numpy(X_test_s.astype(np.float32))).numpy()\n",
    "y_pred = y_pred_s * y_std_size + y_mean_size\n",
    "\n",
    "baseline_cols = [4*k for k in range(K)]\n",
    "baseline = X_test[:, baseline_cols]\n",
    "\n",
    "rmse_per_cluster_model, rmse_per_cluster_base = [], []\n",
    "for k in range(K):\n",
    "    rmse_per_cluster_model.append(float(np.sqrt(mean_squared_error(y_test[:,k], y_pred[:,k]))))\n",
    "    rmse_per_cluster_base.append(float(np.sqrt(mean_squared_error(y_test[:,k], baseline[:,k]))))\n",
    "\n",
    "rmse_overall_model = float(np.sqrt(mean_squared_error(y_test.reshape(-1), y_pred.reshape(-1))))\n",
    "rmse_overall_base  = float(np.sqrt(mean_squared_error(y_test.reshape(-1), baseline.reshape(-1))))\n",
    "\n",
    "for k in range(K):\n",
    "    delta = rmse_per_cluster_base[k] - rmse_per_cluster_model[k]\n",
    "    print(f\"RMSE TX{k} — ANN: {rmse_per_cluster_model[k]:.4f}   RAW: {rmse_per_cluster_base[k]:.4f}   Δ={delta:.4f}\")\n",
    "print(f\"RMSE Overall — ANN: {rmse_overall_model:.4f}   RAW: {rmse_overall_base:.4f}   Δ={rmse_overall_base - rmse_overall_model:.4f}\")\n",
    "print(f\"Best Val Loss (scaled SmoothL1): {best_val:.6f}\")\n",
    "\n",
    "# ------------------------------- MAPE -------------------------------\n",
    "eps = 1e-6\n",
    "for k in range(K):\n",
    "    mape_k = float(np.mean(np.abs((y_test[:,k] - y_pred[:,k]) / np.clip(np.abs(y_test[:,k]), eps, None))))\n",
    "    print(f\"MAPE TX{k} — ANN: {mape_k*100:.2f}%\")\n",
    "mape_overall = float(np.mean(np.abs((y_test - y_pred) / np.clip(np.abs(y_test), eps, None))))\n",
    "print(f\"MAPE Overall — ANN: {mape_overall*100:.2f}%\")\n",
    "\n",
    "# ------------------------------- Save artifacts -------------------------------\n",
    "globals()[\"scaler_X_size\"] = scaler_X_size\n",
    "globals()[\"y_mean_size\"] = y_mean_size\n",
    "globals()[\"y_std_size\"]  = y_std_size\n",
    "globals()[\"size\"] = size\n",
    "globals()[\"K\"] = K\n",
    "\n",
    "# ------------------------------- Plot losses -------------------------------\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(train_losses, label=\"Train\")\n",
    "    plt.plot(val_losses, label=\"Validation\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"SmoothL1 Loss\")\n",
    "    plt.legend(); plt.show()\n",
    "except Exception:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81a784c-e8a4-4c44-a66f-8abb41189199",
   "metadata": {},
   "source": [
    "# ErfC Inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb4f21d-6e2a-4334-9cef-79028c186dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected K = 2 clusters per scene.\n",
      "Prepared 10000 scenes (pre-split).\n",
      "Using TEST set only — scenes: 2000\n",
      "Step 1 — RAW | RMSE: 1.213374 | MAPE: 12.861% | matches: 4000 | skipped scenes: 0\n",
      "Step 2 — Models found | size: ['size_v1'] | angle: ['angle_v1']\n",
      "Step 3 — Predictions obtained.\n",
      "Step 4 — SIZE-ONLY[size_v1] | RMSE: 1.175519 | MAPE: 12.421% | matches: 4000 | skipped scenes: 0\n",
      "Step 4 — ANGLE-ONLY[angle_v1] | RMSE: 0.441286 | MAPE: 5.056% | matches: 4000 | skipped scenes: 0\n",
      "Step 4 — ANGLE+SIZE[angle_v1×size_v1] | RMSE: 0.358540 | MAPE: 3.987% | matches: 4000 | skipped scenes: 0\n",
      "\n",
      "=== Summary (TEST only) ===\n",
      "   variant              model     rmse      mape  matches\n",
      "ANGLE+SIZE angle_v1 × size_v1 0.358540  3.986749     4000\n",
      "ANGLE-ONLY           angle_v1 0.441286  5.056171     4000\n",
      "       RAW                    1.213374 12.860955     4000\n",
      " SIZE-ONLY            size_v1 1.175519 12.420865     4000\n",
      "\n",
      "Saved: inversion_comparison_step_by_step_2Tx_TEST.csv\n"
     ]
    }
   ],
   "source": [
    "# --------------- STEP-BY-STEP COMPARISON PIPELINE ---------------\n",
    "# 1) Evaluate RAW with est_center_i & est_size_i\n",
    "# 2) Build features and feed models (size & angle)\n",
    "# 3) Obtain predicted results (counts & directions)\n",
    "# 4) Evaluate SIZE-ONLY, ANGLE-ONLY, ANGLE+SIZE\n",
    "#\n",
    "# This version generalizes to ANY number of clusters K.\n",
    "# - Features per scene: [size_k, cx_k, cy_k, cz_k] for k=0..K-1  -> 4*K dims\n",
    "# - Size model output: K counts (per cluster)\n",
    "# - Angle model output: 3*K vectors (per cluster), turned into unit directions\n",
    "\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from scipy.special import erfc\n",
    "from scipy.optimize import brentq\n",
    "\n",
    "# ====================== Config ======================\n",
    "#METHOD = \"Density-weighted centers (on KMeans partitions)\"  # change/loop as needed\n",
    "METHOD = \"KMeans centers\"\n",
    "#METHOD = \"MCD-inlier density-weighted centers (on KMeans partitions)\"\n",
    "CFG_PATH = \"./uniform_test/config.csv\"\n",
    "DF_PATH  = \"size_estimation_2Tx.csv\"\n",
    "SPLIT_CSV = \"train_val_test_split_2Tx.csv\"\n",
    "\n",
    "N_EMITTED_PER_TX = 10000\n",
    "R_R_FIXED = 5.0\n",
    "D = 79.4\n",
    "T_HORIZON = 1.0\n",
    "F_EPS = 1e-12  # clamp for F in (0,1)\n",
    "\n",
    "# Optional: register additional models if their variable names differ\n",
    "MODEL_REGISTRY_SIZE = {\n",
    "    # \"size_v1\": dict(model=size,  scaler=scaler_X_size,  y_mean=y_mean_size,  y_std=y_std_size),\n",
    "    # \"size_v2\": dict(model=size2, scaler=scaler_X_size2, y_mean=y_mean_size2, y_std=y_std_size2),\n",
    "}\n",
    "MODEL_REGISTRY_ANGLE = {\n",
    "    # \"angle_v1\": dict(model=model,  scaler=scaler_X,  y_mean=y_mean,  y_std=y_std),\n",
    "    # \"angle_v2\": dict(model=model2, scaler=scaler_X2, y_mean=y_mean2, y_std=y_std2),\n",
    "}\n",
    "\n",
    "# ====================== Helpers ======================\n",
    "def to_vec3(x):\n",
    "    if isinstance(x, list): return [float(x[0]), float(x[1]), float(x[2])]\n",
    "    if isinstance(x, str):  return list(map(float, ast.literal_eval(x)))\n",
    "    raise ValueError(\"Unexpected 3D vector type\")\n",
    "\n",
    "def unit_vec(v, eps=1e-12):\n",
    "    v = np.asarray(v, dtype=float)\n",
    "    n = float(np.linalg.norm(v))\n",
    "    if not np.isfinite(n) or n < eps:\n",
    "        return np.full(3, np.nan)\n",
    "    return v / n\n",
    "\n",
    "def vector_rmse(a, b):\n",
    "    a = np.asarray(a, dtype=float); b = np.asarray(b, dtype=float)\n",
    "    return float(np.sqrt(np.mean((a - b) ** 2))) if len(a) and len(b) else np.nan\n",
    "\n",
    "def vector_mape(a, b, eps=1e-12):\n",
    "    \"\"\"\n",
    "    Mean Absolute Percentage Error for 3D positions (in %).\n",
    "    Uses relative Euclidean error: ||est-true|| / ||true||.\n",
    "    Pairs with ||true|| <= eps are ignored.\n",
    "    \"\"\"\n",
    "    a = np.asarray(a, dtype=float); b = np.asarray(b, dtype=float)\n",
    "    if a.size == 0 or b.size == 0:\n",
    "        return np.nan\n",
    "    A = a.reshape(-1, 3); B = b.reshape(-1, 3)\n",
    "    denom = np.linalg.norm(B, axis=1)\n",
    "    numer = np.linalg.norm(A - B, axis=1)\n",
    "    mask = denom > eps\n",
    "    if not np.any(mask):\n",
    "        return np.nan\n",
    "    return float(100.0 * np.mean(numer[mask] / denom[mask]))\n",
    "\n",
    "def invert_r0_from_fraction(F_hit, r_r, D, t, r0_min=None, r0_max=30):\n",
    "    \"\"\"Solve F = (r_r / r0) * erfc((r0-r_r)/sqrt(4Dt)) for r0; robust with clamp & bracket expansion.\"\"\"\n",
    "    if not np.isfinite(F_hit):\n",
    "        return np.nan\n",
    "    # Keep F within open interval (0,1) for a well-posed inverse\n",
    "    F_hit = float(np.clip(F_hit, F_EPS, 1.0 - F_EPS))\n",
    "\n",
    "    rr = float(r_r)\n",
    "    eps = 1e-9\n",
    "    a = rr + eps if r0_min is None else max(rr + eps, float(r0_min))  # physically r0 > r_r\n",
    "    b = float(r0_max)\n",
    "\n",
    "    def func(r0):\n",
    "        return (rr / r0) * erfc((r0 - rr) / np.sqrt(4.0 * D * t)) - F_hit\n",
    "\n",
    "    fa, fb = func(a), func(b)\n",
    "    tries = 0\n",
    "    # Expand the upper bracket if needed\n",
    "    while np.isfinite(fa) and np.isfinite(fb) and fa * fb > 0 and tries < 100:\n",
    "        b *= 2.0\n",
    "        fb = func(b)\n",
    "        tries += 1\n",
    "\n",
    "    if not (np.isfinite(fa) and np.isfinite(fb)) or fa * fb > 0:\n",
    "        return np.nan\n",
    "\n",
    "    try:\n",
    "        return float(brentq(func, a, b, maxiter=10000))\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def estimate_tx_from_cluster_r0(center_vec, n_received, N_emitted, D, t, r_r=5.0, rx_center=np.array([0.0,0.0,0.0])):\n",
    "    \"\"\"\n",
    "    Invert r0 from F = n_received / N_emitted, then place along direction(center_vec).\n",
    "    If n_received > N_emitted, estimate r0 = r_r directly (saturated case).\n",
    "    \"\"\"\n",
    "    # ---- Direction from receiver to measured cluster center ----\n",
    "    center_vec = np.asarray(center_vec, dtype=float)\n",
    "    rx_center  = np.asarray(rx_center,  dtype=float)\n",
    "    v = center_vec - rx_center\n",
    "    nv = np.linalg.norm(v)\n",
    "    if nv < 1e-12:\n",
    "        return np.array([np.nan, np.nan, np.nan]), np.nan, np.nan\n",
    "    u = v / nv\n",
    "\n",
    "    # ---- Validate counts ----\n",
    "    if not (np.isfinite(n_received) and np.isfinite(N_emitted) and N_emitted > 0):\n",
    "        return np.array([np.nan, np.nan, np.nan]), np.nan, np.nan\n",
    "\n",
    "    # ---- Saturation rule: more received than emitted -> r0 := r_r ----\n",
    "    if n_received > N_emitted:\n",
    "        r0 = float(r_r)\n",
    "        F_used = 1.0  # saturated fraction\n",
    "        tx_est = rx_center + r0 * u\n",
    "        return tx_est, r0, F_used\n",
    "\n",
    "    # ---- Regular path ----\n",
    "    # Clip to [1, N_emitted-1] to stay inside (0,1) after division\n",
    "    n_recv_clip = int(np.clip(int(round(float(n_received))), 1, int(N_emITTED_PER_TX := N_emitted) - 1))\n",
    "    F = float(n_recv_clip) / float(N_emitted)\n",
    "    F = float(np.clip(F, F_EPS, 1.0 - F_EPS))\n",
    "\n",
    "    r0 = invert_r0_from_fraction(F, r_r, D, t)\n",
    "    tx_est = rx_center + r0 * u if np.isfinite(r0) else np.array([0.0, 0.0, 0.0]) * np.nan\n",
    "    return tx_est, r0, F\n",
    "\n",
    "# ====================== Load data & build K-general pairs ======================\n",
    "df = pd.read_csv(DF_PATH)\n",
    "df = df[df[\"method\"] == METHOD].copy()\n",
    "df[\"est_center\"] = df[\"est_center\"].apply(to_vec3)\n",
    "df[\"est_size\"]   = df[\"est_size\"].astype(float)\n",
    "df[\"tx_index\"]   = df[\"tx_index\"].astype(int)\n",
    "\n",
    "cfg = pd.read_csv(CFG_PATH)\n",
    "if \"file_index\" not in cfg.columns:\n",
    "    cfg = cfg.reset_index().rename(columns={\"index\":\"file_index\"})\n",
    "\n",
    "# Build truth map and infer K (must be consistent across scenes)\n",
    "truth_map = {}\n",
    "K = None\n",
    "for _, r in cfg.iterrows():\n",
    "    centers = r[\"tx_centers\"]\n",
    "    centers = ast.literal_eval(centers) if isinstance(centers, str) else centers\n",
    "    centers = np.asarray([list(map(float, c)) for c in centers], dtype=float)\n",
    "    truth_map[int(r[\"file_index\"])] = centers\n",
    "    if K is None:\n",
    "        K = centers.shape[0]\n",
    "    else:\n",
    "        assert K == centers.shape[0], f\"Inconsistent K across files: got {centers.shape[0]} vs {K}\"\n",
    "\n",
    "print(f\"Detected K = {K} clusters per scene.\")\n",
    "\n",
    "# Keep only scenes present in truth and having all tx_index {0..K-1}\n",
    "df = df[df[\"file_index\"].isin(truth_map.keys())]\n",
    "\n",
    "def has_all_k(s):\n",
    "    return set(s[\"tx_index\"].unique()) == set(range(K))\n",
    "\n",
    "g = (df.groupby([\"file_index\"], as_index=False)\n",
    "       .filter(has_all_k)\n",
    "       .sort_values([\"file_index\",\"tx_index\"])\n",
    "       .reset_index(drop=True))\n",
    "\n",
    "# Build a compact \"pairs\" DataFrame with arrays per scene\n",
    "rows = []\n",
    "for fid, s in g.groupby(\"file_index\"):\n",
    "    s = s.sort_values(\"tx_index\")\n",
    "    if list(s[\"tx_index\"]) != list(range(K)):\n",
    "        continue\n",
    "    est_sizes = s[\"est_size\"].astype(float).to_numpy()                  # (K,)\n",
    "    est_centers = np.vstack(s[\"est_center\"].tolist()).astype(float)     # (K,3)\n",
    "    rows.append({\"file_index\": int(fid), \"est_sizes\": est_sizes, \"est_centers\": est_centers})\n",
    "\n",
    "pairs = pd.DataFrame(rows)\n",
    "if len(pairs) == 0:\n",
    "    raise ValueError(f\"No complete scenes with K={K} for method '{METHOD}'.\")\n",
    "print(f\"Prepared {len(pairs)} scenes (pre-split).\")\n",
    "\n",
    "# ====================== TEST SPLIT FILTER ======================\n",
    "split_df = pd.read_csv(SPLIT_CSV)\n",
    "test_files = set(split_df.loc[split_df[\"split\"].str.lower() == \"test\", \"file_index\"].astype(int))\n",
    "pairs = (pairs[pairs[\"file_index\"].isin(test_files)]\n",
    "         .sort_values(\"file_index\").reset_index(drop=True))\n",
    "if len(pairs) == 0:\n",
    "    raise ValueError(\"No test scenes after filtering by split CSV.\")\n",
    "print(f\"Using TEST set only — scenes: {len(pairs)}\")\n",
    "\n",
    "# ====================== Step 1 — Evaluate RAW ======================\n",
    "raw_est, raw_true = [], []\n",
    "raw_skipped = 0\n",
    "for _, r in pairs.iterrows():\n",
    "    T = np.asarray(truth_map[int(r[\"file_index\"])], dtype=float)  # (K,3)\n",
    "    E = []\n",
    "    for k in range(K):\n",
    "        c_vec = r[\"est_centers\"][k]\n",
    "        n_recv = r[\"est_sizes\"][k]\n",
    "        tx, _, _ = estimate_tx_from_cluster_r0(\n",
    "            center_vec=c_vec, n_received=float(n_recv),\n",
    "            N_emitted=N_EMITTED_PER_TX, D=D, t=T_HORIZON,\n",
    "            r_r=R_R_FIXED, rx_center=np.array([0.,0.,0.])\n",
    "        )\n",
    "        E.append(tx)\n",
    "    E = np.asarray(E, dtype=float)  # (K,3)\n",
    "    if not (np.all(np.isfinite(E)) and np.all(np.isfinite(T)) and E.shape==(K,3) and T.shape==(K,3)):\n",
    "        raw_skipped += 1\n",
    "        continue\n",
    "    cost = cdist(E, T, metric=\"euclidean\")\n",
    "    r_ind, c_ind = linear_sum_assignment(cost)\n",
    "    raw_est.extend(E[r_ind]); raw_true.extend(T[c_ind])\n",
    "\n",
    "rmse_raw = vector_rmse(raw_est, raw_true)\n",
    "mape_raw = vector_mape(raw_est, raw_true)\n",
    "print(f\"Step 1 — RAW | RMSE: {rmse_raw:.6f} | MAPE: {mape_raw:.3f}% | matches: {len(raw_est)} | skipped scenes: {raw_skipped}\")\n",
    "\n",
    "# ====================== Step 2 — Build features & discover models ======================\n",
    "def row_to_feat(r):\n",
    "    # Flatten blocks of 4 per cluster: [size_k, cx_k, cy_k, cz_k] for k=0..K-1\n",
    "    feat = []\n",
    "    for k in range(K):\n",
    "        feat.append(float(r[\"est_sizes\"][k]))\n",
    "        feat.extend(list(map(float, r[\"est_centers\"][k])))\n",
    "    return feat\n",
    "\n",
    "X4K = np.array([row_to_feat(r) for _, r in pairs.iterrows()], dtype=float)  # (N, 4*K)\n",
    "\n",
    "# Discover models in memory (or use registries filled above)\n",
    "def try_add_size_model(reg, name, model_name, scaler_name, mean_name, std_name, globs):\n",
    "    if all(k in globs for k in [model_name, scaler_name, mean_name, std_name]):\n",
    "        reg[name] = dict(model=globs[model_name], scaler=globs[scaler_name],\n",
    "                         y_mean=globs[mean_name], y_std=globs[std_name])\n",
    "\n",
    "def try_add_angle_model(reg, name, model_name, scaler_name, mean_name, std_name, globs):\n",
    "    if all(k in globs for k in [model_name, scaler_name, mean_name, std_name]):\n",
    "        reg[name] = dict(model=globs[model_name], scaler=globs[scaler_name],\n",
    "                         y_mean=globs[mean_name], y_std=globs[std_name])\n",
    "\n",
    "size_models = dict(MODEL_REGISTRY_SIZE)\n",
    "angle_models = dict(MODEL_REGISTRY_ANGLE)\n",
    "G = globals()\n",
    "try_add_size_model(size_models,  \"size_v1\", \"size\",  \"scaler_X_size\",  \"y_mean_size\",  \"y_std_size\",  G)\n",
    "try_add_size_model(size_models,  \"size_v2\", \"size2\", \"scaler_X_size2\", \"y_mean_size2\", \"y_std_size2\", G)\n",
    "try_add_angle_model(angle_models,\"angle_v1\",\"model\", \"scaler_X\",       \"y_mean\",       \"y_std\",       G)\n",
    "try_add_angle_model(angle_models,\"angle_v2\",\"model2\",\"scaler_X2\",      \"y_mean2\",      \"y_std2\",      G)\n",
    "\n",
    "print(f\"Step 2 — Models found | size: {list(size_models.keys()) or '(none)'} | angle: {list(angle_models.keys()) or '(none)'}\")\n",
    "\n",
    "# ====================== Step 3 — Predict (size counts & angle directions) ======================\n",
    "def predict_sizes(X, spec, K_expected):\n",
    "    mdl, scl, ym, ys = spec[\"model\"], spec[\"scaler\"], spec[\"y_mean\"], spec[\"y_std\"]\n",
    "    Xs = scl.transform(X)\n",
    "    with torch.no_grad():\n",
    "        y_s = mdl(torch.tensor(Xs, dtype=torch.float32)).cpu().numpy()  # (N, K_m)\n",
    "    y = y_s * ys + ym  # de-standardize\n",
    "    # Guard against mismatched K\n",
    "    if y.shape[1] != K_expected:\n",
    "        print(f\"[WARN] Skipping size model (out_dim={y.shape[1]} != K={K_expected}).\")\n",
    "        return None\n",
    "    # Return floats; downstream estimator clamps to physical range\n",
    "    return np.clip(y.astype(float), 1.0, float(N_EMITTED_PER_TX))\n",
    "\n",
    "def predict_angles(X, spec, K_expected):\n",
    "    mdl, scl, ym, ys = spec[\"model\"], spec[\"scaler\"], spec[\"y_mean\"], spec[\"y_std\"]\n",
    "    Xs = scl.transform(X)\n",
    "    with torch.no_grad():\n",
    "        y_s = mdl(torch.tensor(Xs, dtype=torch.float32)).cpu().numpy()  # (N, 3*K_m)\n",
    "    y = y_s * ys + ym\n",
    "    if y.shape[1] % 3 != 0:\n",
    "        print(f\"[WARN] Angle model output dim {y.shape[1]} not divisible by 3; skipping.\")\n",
    "        return None\n",
    "    K_m = y.shape[1] // 3\n",
    "    if K_m != K_expected:\n",
    "        print(f\"[WARN] Skipping angle model (K_out={K_m} != K={K_expected}).\")\n",
    "        return None\n",
    "    # Convert to unit directions (N, K, 3)\n",
    "    y = y.reshape(y.shape[0], K_m, 3)\n",
    "    dirs = np.zeros_like(y)\n",
    "    for i in range(y.shape[0]):\n",
    "        for k in range(K_m):\n",
    "            dirs[i, k] = unit_vec(y[i, k])\n",
    "    return dirs  # (N, K, 3)\n",
    "\n",
    "size_preds = {}\n",
    "for name, spec in size_models.items():\n",
    "    pred = predict_sizes(X4K, spec, K_expected=K)\n",
    "    if pred is not None:\n",
    "        size_preds[name] = pred\n",
    "\n",
    "angle_preds = {}\n",
    "for name, spec in angle_models.items():\n",
    "    pred = predict_angles(X4K, spec, K_expected=K)\n",
    "    if pred is not None:\n",
    "        angle_preds[name] = pred\n",
    "\n",
    "print(\"Step 3 — Predictions obtained.\")\n",
    "\n",
    "# ====================== Step 4 — Evaluate predicted variants ======================\n",
    "results = []\n",
    "\n",
    "# SIZE-ONLY (use raw dirs via est_centers, predicted counts)\n",
    "for name_sz, y_counts in size_preds.items():\n",
    "    est, tru = [], []\n",
    "    skipped = 0\n",
    "    for j, (_, r) in enumerate(pairs.iterrows()):\n",
    "        T = np.asarray(truth_map[int(r[\"file_index\"])], dtype=float)  # (K,3)\n",
    "        E = []\n",
    "        for k in range(K):\n",
    "            tx, _, _ = estimate_tx_from_cluster_r0(\n",
    "                center_vec=r[\"est_centers\"][k],\n",
    "                n_received=float(y_counts[j, k]),  # positional index!\n",
    "                N_emitted=N_EMITTED_PER_TX, D=D, t=T_HORIZON,\n",
    "                r_r=R_R_FIXED, rx_center=np.array([0.,0.,0.])\n",
    "            )\n",
    "            E.append(tx)\n",
    "        E = np.asarray(E, dtype=float)  # (K,3)\n",
    "        if not (np.all(np.isfinite(E)) and np.all(np.isfinite(T))):\n",
    "            skipped += 1\n",
    "            continue\n",
    "        cost = cdist(E, T, metric=\"euclidean\")\n",
    "        r_ind, c_ind = linear_sum_assignment(cost)\n",
    "        est.extend(E[r_ind]); tru.extend(T[c_ind])\n",
    "    rmse = vector_rmse(est, tru)\n",
    "    mape = vector_mape(est, tru)\n",
    "    print(f\"Step 4 — SIZE-ONLY[{name_sz}] | RMSE: {rmse:.6f} | MAPE: {mape:.3f}% | matches: {len(est)} | skipped scenes: {skipped}\")\n",
    "    results.append(dict(variant=\"SIZE-ONLY\", model=name_sz, rmse=rmse, mape=mape, matches=len(est)))\n",
    "\n",
    "# ANGLE-ONLY (use predicted dirs, observed counts to set radii via estimate_tx_from_cluster_r0)\n",
    "for name_ang, dirs in angle_preds.items():\n",
    "    est, tru = [], []\n",
    "    skipped = 0\n",
    "\n",
    "    for j, (_, r) in enumerate(pairs.iterrows()):\n",
    "        T = np.asarray(truth_map[int(r[\"file_index\"])], dtype=float)  # (K,3)\n",
    "        if T.shape[0] != K or not np.all(np.isfinite(T)):\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        tx_estimates = []\n",
    "        ok = True\n",
    "\n",
    "        for k in range(K):\n",
    "            # direction for this cluster (ensure unit length)\n",
    "            dir_k = np.asarray(dirs[j][k], dtype=float)\n",
    "            n = np.linalg.norm(dir_k)\n",
    "            if not np.isfinite(n) or n < 1e-12:\n",
    "                ok = False\n",
    "                break\n",
    "            dir_k = dir_k / n\n",
    "\n",
    "            # observed count for this cluster\n",
    "            n_recv = float(r[\"est_sizes\"][k])\n",
    "\n",
    "            # estimate tx position along dir_k based on r0 inversion\n",
    "            tx_est, r0, F_used = estimate_tx_from_cluster_r0(\n",
    "                center_vec=dir_k,                 # just a direction; function normalizes anyway\n",
    "                n_received=n_recv,\n",
    "                N_emitted=N_EMITTED_PER_TX,\n",
    "                D=D,\n",
    "                t=T_HORIZON,\n",
    "                r_r=R_R_FIXED,\n",
    "                rx_center=np.array([0.0, 0.0, 0.0])  # receiver at origin\n",
    "            )\n",
    "\n",
    "            if not np.all(np.isfinite(tx_est)):\n",
    "                ok = False\n",
    "                break\n",
    "\n",
    "            tx_estimates.append(tx_est)\n",
    "\n",
    "        if not ok:\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        E = np.vstack(tx_estimates)  # (K,3)\n",
    "        cost = cdist(E, T, metric=\"euclidean\")\n",
    "        r_ind, c_ind = linear_sum_assignment(cost)\n",
    "        est.extend(E[r_ind]); tru.extend(T[c_ind])\n",
    "\n",
    "    rmse = vector_rmse(est, tru)\n",
    "    mape = vector_mape(est, tru)\n",
    "    print(f\"Step 4 — ANGLE-ONLY[{name_ang}] | RMSE: {rmse:.6f} | MAPE: {mape:.3f}% | matches: {len(est)} | skipped scenes: {skipped}\")\n",
    "    results.append(dict(variant=\"ANGLE-ONLY\", model=name_ang, rmse=rmse, mape=mape, matches=len(est)))\n",
    "\n",
    "# ANGLE+SIZE (use predicted dirs and predicted counts via r0 inversion)\n",
    "for name_ang, dirs in angle_preds.items():\n",
    "    for name_sz, y_counts in size_preds.items():\n",
    "        est, tru = [], []\n",
    "        skipped = 0\n",
    "\n",
    "        for j, (_, r) in enumerate(pairs.iterrows()):\n",
    "            T = np.asarray(truth_map[int(r[\"file_index\"])], dtype=float)  # (K,3)\n",
    "            if T.shape[0] != K or not np.all(np.isfinite(T)):\n",
    "                skipped += 1\n",
    "                continue\n",
    "\n",
    "            tx_estimates = []\n",
    "            ok = True\n",
    "\n",
    "            for k in range(K):\n",
    "                # direction for this cluster -> ensure unit vector\n",
    "                dir_k = np.asarray(dirs[j][k], dtype=float)\n",
    "                nrm = np.linalg.norm(dir_k)\n",
    "                if not np.isfinite(nrm) or nrm < 1e-12:\n",
    "                    ok = False\n",
    "                    break\n",
    "                dir_k = dir_k / nrm\n",
    "\n",
    "                # predicted count for this cluster (float; function will clamp)\n",
    "                n_recv = float(y_counts[j, k])\n",
    "\n",
    "                # estimate tx position along dir_k based on r0 inversion\n",
    "                tx_est, r0, F_used = estimate_tx_from_cluster_r0(\n",
    "                    center_vec=dir_k,                 # direction is enough; function normalizes again\n",
    "                    n_received=n_recv,\n",
    "                    N_emitted=N_EMITTED_PER_TX,\n",
    "                    D=D,\n",
    "                    t=T_HORIZON,\n",
    "                    r_r=R_R_FIXED,\n",
    "                    rx_center=np.array([0.0, 0.0, 0.0])  # receiver at origin\n",
    "                )\n",
    "\n",
    "                if not np.all(np.isfinite(tx_est)):\n",
    "                    ok = False\n",
    "                    break\n",
    "\n",
    "                tx_estimates.append(tx_est)\n",
    "\n",
    "            if not ok:\n",
    "                skipped += 1\n",
    "                continue\n",
    "\n",
    "            E = np.vstack(tx_estimates)  # (K,3)\n",
    "            cost = cdist(E, T, metric=\"euclidean\")\n",
    "            r_ind, c_ind = linear_sum_assignment(cost)\n",
    "            est.extend(E[r_ind]); tru.extend(T[c_ind])\n",
    "\n",
    "        rmse = vector_rmse(est, tru)\n",
    "        mape = vector_mape(est, tru)\n",
    "        print(f\"Step 4 — ANGLE+SIZE[{name_ang}×{name_sz}] | RMSE: {rmse:.6f} | MAPE: {mape:.3f}% | matches: {len(est)} | skipped scenes: {skipped}\")\n",
    "        results.append(dict(variant=\"ANGLE+SIZE\", model=f\"{name_ang} × {name_sz}\",\n",
    "                            rmse=rmse, mape=mape, matches=len(est)))\n",
    "\n",
    "# ====================== Summary & Save ======================\n",
    "summary = [dict(variant=\"RAW\", model=\"\", rmse=rmse_raw, mape=mape_raw, matches=len(raw_est))]\n",
    "summary.extend(results)\n",
    "res_df = pd.DataFrame(summary).sort_values([\"variant\",\"model\"]).reset_index(drop=True)\n",
    "print(\"\\n=== Summary (TEST only) ===\")\n",
    "print(res_df.to_string(index=False))\n",
    "\n",
    "out_csv = \"inversion_comparison_step_by_step_2Tx_TEST.csv\"\n",
    "res_df.to_csv(out_csv, index=False)\n",
    "print(f\"\\nSaved: {out_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849d9926-8924-41d4-85e4-7e431cb54275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected K = 2 clusters per scene.\n",
      "Prepared 10000 scenes (pre-split).\n",
      "Using TEST set only — scenes: 2000\n",
      "Step 1 — RAW | RMSE: 1.213374 | MAPE: 12.861% | matches: 4000 | skipped scenes: 0\n",
      "Step 2 — Models found | size: ['size_v1'] | angle: ['angle_v1']\n",
      "Step 3 — Predictions obtained.\n",
      "Step 4 — SIZE-ONLY[size_v1] | RMSE: 1.175519 | MAPE: 12.421% | matches: 4000 | skipped scenes: 0\n",
      "Step 4 — ANGLE-ONLY[angle_v1] | RMSE: 0.441286 | MAPE: 5.056% | matches: 4000 | skipped scenes: 0\n",
      "Step 4 — ANGLE+SIZE[angle_v1×size_v1] | RMSE: 0.358540 | MAPE: 3.987% | matches: 4000 | skipped scenes: 0\n",
      "\n",
      "=== Summary (TEST only) ===\n",
      "   variant              model     rmse      mape  matches\n",
      "ANGLE+SIZE angle_v1 × size_v1 0.358540  3.986749     4000\n",
      "ANGLE-ONLY           angle_v1 0.441286  5.056171     4000\n",
      "       RAW                    1.213374 12.860955     4000\n",
      " SIZE-ONLY            size_v1 1.175519 12.420865     4000\n",
      "\n",
      "Saved: inversion_comparison_step_by_step_2Tx_TEST.csv\n",
      "[RAW-OTHER] Density-weighted centers (on KMeans partitions) | RMSE: 0.782876 | MAPE: 7.356% | matches: 4000 | skipped scenes: 0\n",
      "[RAW-OTHER] MCD-inlier density-weighted centers (on KMeans partitions) | RMSE: 0.753806 | MAPE: 7.515% | matches: 4000 | skipped scenes: 0\n",
      "[RAW-OTHER] Robust (MinCovDet) centers (on KMeans partitions) | RMSE: 0.805381 | MAPE: 7.899% | matches: 4000 | skipped scenes: 0\n",
      "\n",
      "Saved RAW other-methods results: raw_results_other_methods_2Tx_TEST.csv\n"
     ]
    }
   ],
   "source": [
    "# --------------- STEP-BY-STEP COMPARISON PIPELINE ---------------\n",
    "# 1) Evaluate RAW with est_center_i & est_size_i\n",
    "# 2) Build features and feed models (size & angle)\n",
    "# 3) Obtain predicted results (counts & directions)\n",
    "# 4) Evaluate SIZE-ONLY, ANGLE-ONLY, ANGLE+SIZE\n",
    "#\n",
    "# This version generalizes to ANY number of clusters K.\n",
    "# - Features per scene: [size_k, cx_k, cy_k, cz_k] for k=0..K-1  -> 4*K dims\n",
    "# - Size model output: K counts (per cluster)\n",
    "# - Angle model output: 3*K vectors (per cluster), turned into unit directions\n",
    "\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from scipy.special import erfc\n",
    "from scipy.optimize import brentq\n",
    "\n",
    "# ====================== Config ======================\n",
    "#METHOD = \"Density-weighted centers (on KMeans partitions)\"  # change/loop as needed\n",
    "METHOD = \"KMeans centers\"\n",
    "#METHOD = \"MCD-inlier density-weighted centers (on KMeans partitions)\"\n",
    "CFG_PATH = \"./uniform_test/config.csv\"\n",
    "DF_PATH  = \"size_estimation_2Tx.csv\"\n",
    "SPLIT_CSV = \"train_val_test_split_2Tx.csv\"\n",
    "\n",
    "N_EMITTED_PER_TX = 10000\n",
    "R_R_FIXED = 5.0\n",
    "D = 79.4\n",
    "T_HORIZON = 1.0\n",
    "F_EPS = 1e-12  # clamp for F in (0,1)\n",
    "\n",
    "# Optional: register additional models if their variable names differ\n",
    "MODEL_REGISTRY_SIZE = {\n",
    "    # \"size_v1\": dict(model=size,  scaler=scaler_X_size,  y_mean=y_mean_size,  y_std=y_std_size),\n",
    "    # \"size_v2\": dict(model=size2, scaler=scaler_X_size2, y_mean=y_mean_size2, y_std=y_std_size2),\n",
    "}\n",
    "MODEL_REGISTRY_ANGLE = {\n",
    "    # \"angle_v1\": dict(model=model,  scaler=scaler_X,  y_mean=y_mean,  y_std=y_std),\n",
    "    # \"angle_v2\": dict(model=model2, scaler=scaler_X2, y_mean=y_mean2, y_std=y_std2),\n",
    "}\n",
    "\n",
    "# ====================== Helpers ======================\n",
    "def to_vec3(x):\n",
    "    if isinstance(x, list): return [float(x[0]), float(x[1]), float(x[2])]\n",
    "    if isinstance(x, str):  return list(map(float, ast.literal_eval(x)))\n",
    "    raise ValueError(\"Unexpected 3D vector type\")\n",
    "\n",
    "def unit_vec(v, eps=1e-12):\n",
    "    v = np.asarray(v, dtype=float)\n",
    "    n = float(np.linalg.norm(v))\n",
    "    if not np.isfinite(n) or n < eps:\n",
    "        return np.full(3, np.nan)\n",
    "    return v / n\n",
    "\n",
    "def vector_rmse(a, b):\n",
    "    a = np.asarray(a, dtype=float); b = np.asarray(b, dtype=float)\n",
    "    return float(np.sqrt(np.mean((a - b) ** 2))) if len(a) and len(b) else np.nan\n",
    "\n",
    "def vector_mape(a, b, eps=1e-12):\n",
    "    \"\"\"\n",
    "    Mean Absolute Percentage Error for 3D positions (in %).\n",
    "    Uses relative Euclidean error: ||est-true|| / ||true||.\n",
    "    Pairs with ||true|| <= eps are ignored.\n",
    "    \"\"\"\n",
    "    a = np.asarray(a, dtype=float); b = np.asarray(b, dtype=float)\n",
    "    if a.size == 0 or b.size == 0:\n",
    "        return np.nan\n",
    "    A = a.reshape(-1, 3); B = b.reshape(-1, 3)\n",
    "    denom = np.linalg.norm(B, axis=1)\n",
    "    numer = np.linalg.norm(A - B, axis=1)\n",
    "    mask = denom > eps\n",
    "    if not np.any(mask):\n",
    "        return np.nan\n",
    "    return float(100.0 * np.mean(numer[mask] / denom[mask]))\n",
    "\n",
    "def invert_r0_from_fraction(F_hit, r_r, D, t, r0_min=None, r0_max=30):\n",
    "    \"\"\"Solve F = (r_r / r0) * erfc((r0-r_r)/sqrt(4Dt)) for r0; robust with clamp & bracket expansion.\"\"\"\n",
    "    if not np.isfinite(F_hit):\n",
    "        return np.nan\n",
    "    # Keep F within open interval (0,1) for a well-posed inverse\n",
    "    F_hit = float(np.clip(F_hit, F_EPS, 1.0 - F_EPS))\n",
    "\n",
    "    rr = float(r_r)\n",
    "    eps = 1e-9\n",
    "    a = rr + eps if r0_min is None else max(rr + eps, float(r0_min))  # physically r0 > r_r\n",
    "    b = float(r0_max)\n",
    "\n",
    "    def func(r0):\n",
    "        return (rr / r0) * erfc((r0 - rr) / np.sqrt(4.0 * D * t)) - F_hit\n",
    "\n",
    "    fa, fb = func(a), func(b)\n",
    "    tries = 0\n",
    "    # Expand the upper bracket if needed\n",
    "    while np.isfinite(fa) and np.isfinite(fb) and fa * fb > 0 and tries < 100:\n",
    "        b *= 2.0\n",
    "        fb = func(b)\n",
    "        tries += 1\n",
    "\n",
    "    if not (np.isfinite(fa) and np.isfinite(fb)) or fa * fb > 0:\n",
    "        return np.nan\n",
    "\n",
    "    try:\n",
    "        return float(brentq(func, a, b, maxiter=10000))\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def estimate_tx_from_cluster_r0(center_vec, n_received, N_emitted, D, t, r_r=5.0, rx_center=np.array([0.0,0.0,0.0])):\n",
    "    \"\"\"\n",
    "    Invert r0 from F = n_received / N_emitted, then place along direction(center_vec).\n",
    "    If n_received > N_emitted, estimate r0 = r_r directly (saturated case).\n",
    "    \"\"\"\n",
    "    # ---- Direction from receiver to measured cluster center ----\n",
    "    center_vec = np.asarray(center_vec, dtype=float)\n",
    "    rx_center  = np.asarray(rx_center,  dtype=float)\n",
    "    v = center_vec - rx_center\n",
    "    nv = np.linalg.norm(v)\n",
    "    if nv < 1e-12:\n",
    "        return np.array([np.nan, np.nan, np.nan]), np.nan, np.nan\n",
    "    u = v / nv\n",
    "\n",
    "    # ---- Validate counts ----\n",
    "    if not (np.isfinite(n_received) and np.isfinite(N_emitted) and N_emitted > 0):\n",
    "        return np.array([np.nan, np.nan, np.nan]), np.nan, np.nan\n",
    "\n",
    "    # ---- Saturation rule: more received than emitted -> r0 := r_r ----\n",
    "    if n_received > N_emitted:\n",
    "        r0 = float(r_r)\n",
    "        F_used = 1.0  # saturated fraction\n",
    "        tx_est = rx_center + r0 * u\n",
    "        return tx_est, r0, F_used\n",
    "\n",
    "    # ---- Regular path ----\n",
    "    # Clip to [1, N_emitted-1] to stay inside (0,1) after division\n",
    "    n_recv_clip = int(np.clip(int(round(float(n_received))), 1, int(N_emITTED_PER_TX := N_emitted) - 1))\n",
    "    F = float(n_recv_clip) / float(N_emitted)\n",
    "    F = float(np.clip(F, F_EPS, 1.0 - F_EPS))\n",
    "\n",
    "    r0 = invert_r0_from_fraction(F, r_r, D, t)\n",
    "    tx_est = rx_center + r0 * u if np.isfinite(r0) else np.array([0.0, 0.0, 0.0]) * np.nan\n",
    "    return tx_est, r0, F\n",
    "\n",
    "# ====================== Load data & build K-general pairs ======================\n",
    "df = pd.read_csv(DF_PATH)\n",
    "df = df[df[\"method\"] == METHOD].copy()\n",
    "df[\"est_center\"] = df[\"est_center\"].apply(to_vec3)\n",
    "df[\"est_size\"]   = df[\"est_size\"].astype(float)\n",
    "df[\"tx_index\"]   = df[\"tx_index\"].astype(int)\n",
    "\n",
    "cfg = pd.read_csv(CFG_PATH)\n",
    "if \"file_index\" not in cfg.columns:\n",
    "    cfg = cfg.reset_index().rename(columns={\"index\":\"file_index\"})\n",
    "\n",
    "# Build truth map and infer K (must be consistent across scenes)\n",
    "truth_map = {}\n",
    "K = None\n",
    "for _, r in cfg.iterrows():\n",
    "    centers = r[\"tx_centers\"]\n",
    "    centers = ast.literal_eval(centers) if isinstance(centers, str) else centers\n",
    "    centers = np.asarray([list(map(float, c)) for c in centers], dtype=float)\n",
    "    truth_map[int(r[\"file_index\"])] = centers\n",
    "    if K is None:\n",
    "        K = centers.shape[0]\n",
    "    else:\n",
    "        assert K == centers.shape[0], f\"Inconsistent K across files: got {centers.shape[0]} vs {K}\"\n",
    "\n",
    "print(f\"Detected K = {K} clusters per scene.\")\n",
    "\n",
    "# Keep only scenes present in truth and having all tx_index {0..K-1}\n",
    "df = df[df[\"file_index\"].isin(truth_map.keys())]\n",
    "\n",
    "def has_all_k(s):\n",
    "    return set(s[\"tx_index\"].unique()) == set(range(K))\n",
    "\n",
    "g = (df.groupby([\"file_index\"], as_index=False)\n",
    "       .filter(has_all_k)\n",
    "       .sort_values([\"file_index\",\"tx_index\"])\n",
    "       .reset_index(drop=True))\n",
    "\n",
    "# Build a compact \"pairs\" DataFrame with arrays per scene\n",
    "rows = []\n",
    "for fid, s in g.groupby(\"file_index\"):\n",
    "    s = s.sort_values(\"tx_index\")\n",
    "    if list(s[\"tx_index\"]) != list(range(K)):\n",
    "        continue\n",
    "    est_sizes = s[\"est_size\"].astype(float).to_numpy()                  # (K,)\n",
    "    est_centers = np.vstack(s[\"est_center\"].tolist()).astype(float)     # (K,3)\n",
    "    rows.append({\"file_index\": int(fid), \"est_sizes\": est_sizes, \"est_centers\": est_centers})\n",
    "\n",
    "pairs = pd.DataFrame(rows)\n",
    "if len(pairs) == 0:\n",
    "    raise ValueError(f\"No complete scenes with K={K} for method '{METHOD}'.\")\n",
    "print(f\"Prepared {len(pairs)} scenes (pre-split).\")\n",
    "\n",
    "# ====================== TEST SPLIT FILTER ======================\n",
    "split_df = pd.read_csv(SPLIT_CSV)\n",
    "test_files = set(split_df.loc[split_df[\"split\"].str.lower() == \"test\", \"file_index\"].astype(int))\n",
    "pairs = (pairs[pairs[\"file_index\"].isin(test_files)]\n",
    "         .sort_values(\"file_index\").reset_index(drop=True))\n",
    "if len(pairs) == 0:\n",
    "    raise ValueError(\"No test scenes after filtering by split CSV.\")\n",
    "print(f\"Using TEST set only — scenes: {len(pairs)}\")\n",
    "\n",
    "# ====================== Step 1 — Evaluate RAW ======================\n",
    "raw_est, raw_true = [], []\n",
    "raw_skipped = 0\n",
    "for _, r in pairs.iterrows():\n",
    "    T = np.asarray(truth_map[int(r[\"file_index\"])], dtype=float)  # (K,3)\n",
    "    E = []\n",
    "    for k in range(K):\n",
    "        c_vec = r[\"est_centers\"][k]\n",
    "        n_recv = r[\"est_sizes\"][k]\n",
    "        tx, _, _ = estimate_tx_from_cluster_r0(\n",
    "            center_vec=c_vec, n_received=float(n_recv),\n",
    "            N_emitted=N_EMITTED_PER_TX, D=D, t=T_HORIZON,\n",
    "            r_r=R_R_FIXED, rx_center=np.array([0.,0.,0.])\n",
    "        )\n",
    "        E.append(tx)\n",
    "    E = np.asarray(E, dtype=float)  # (K,3)\n",
    "    if not (np.all(np.isfinite(E)) and np.all(np.isfinite(T)) and E.shape==(K,3) and T.shape==(K,3)):\n",
    "        raw_skipped += 1\n",
    "        continue\n",
    "    cost = cdist(E, T, metric=\"euclidean\")\n",
    "    r_ind, c_ind = linear_sum_assignment(cost)\n",
    "    raw_est.extend(E[r_ind]); raw_true.extend(T[c_ind])\n",
    "\n",
    "rmse_raw = vector_rmse(raw_est, raw_true)\n",
    "mape_raw = vector_mape(raw_est, raw_true)\n",
    "print(f\"Step 1 — RAW | RMSE: {rmse_raw:.6f} | MAPE: {mape_raw:.3f}% | matches: {len(raw_est)} | skipped scenes: {raw_skipped}\")\n",
    "\n",
    "# ====================== Step 2 — Build features & discover models ======================\n",
    "def row_to_feat(r):\n",
    "    # Flatten blocks of 4 per cluster: [size_k, cx_k, cy_k, cz_k] for k=0..K-1\n",
    "    feat = []\n",
    "    for k in range(K):\n",
    "        feat.append(float(r[\"est_sizes\"][k]))\n",
    "        feat.extend(list(map(float, r[\"est_centers\"][k])))\n",
    "    return feat\n",
    "\n",
    "X4K = np.array([row_to_feat(r) for _, r in pairs.iterrows()], dtype=float)  # (N, 4*K)\n",
    "\n",
    "# Discover models in memory (or use registries filled above)\n",
    "def try_add_size_model(reg, name, model_name, scaler_name, mean_name, std_name, globs):\n",
    "    if all(k in globs for k in [model_name, scaler_name, mean_name, std_name]):\n",
    "        reg[name] = dict(model=globs[model_name], scaler=globs[scaler_name],\n",
    "                         y_mean=globs[mean_name], y_std=globs[std_name])\n",
    "\n",
    "def try_add_angle_model(reg, name, model_name, scaler_name, mean_name, std_name, globs):\n",
    "    if all(k in globs for k in [model_name, scaler_name, mean_name, std_name]):\n",
    "        reg[name] = dict(model=globs[model_name], scaler=globs[scaler_name],\n",
    "                         y_mean=globs[mean_name], y_std=globs[std_name])\n",
    "\n",
    "size_models = dict(MODEL_REGISTRY_SIZE)\n",
    "angle_models = dict(MODEL_REGISTRY_ANGLE)\n",
    "G = globals()\n",
    "try_add_size_model(size_models,  \"size_v1\", \"size\",  \"scaler_X_size\",  \"y_mean_size\",  \"y_std_size\",  G)\n",
    "try_add_size_model(size_models,  \"size_v2\", \"size2\", \"scaler_X_size2\", \"y_mean_size2\", \"y_std_size2\", G)\n",
    "try_add_angle_model(angle_models,\"angle_v1\",\"model\", \"scaler_X\",       \"y_mean\",       \"y_std\",       G)\n",
    "try_add_angle_model(angle_models,\"angle_v2\",\"model2\",\"scaler_X2\",      \"y_mean2\",      \"y_std2\",      G)\n",
    "\n",
    "print(f\"Step 2 — Models found | size: {list(size_models.keys()) or '(none)'} | angle: {list(angle_models.keys()) or '(none)'}\")\n",
    "\n",
    "# ====================== Step 3 — Predict (size counts & angle directions) ======================\n",
    "def predict_sizes(X, spec, K_expected):\n",
    "    mdl, scl, ym, ys = spec[\"model\"], spec[\"scaler\"], spec[\"y_mean\"], spec[\"y_std\"]\n",
    "    Xs = scl.transform(X)\n",
    "    with torch.no_grad():\n",
    "        y_s = mdl(torch.tensor(Xs, dtype=torch.float32)).cpu().numpy()  # (N, K_m)\n",
    "    y = y_s * ys + ym  # de-standardize\n",
    "    # Guard against mismatched K\n",
    "    if y.shape[1] != K_expected:\n",
    "        print(f\"[WARN] Skipping size model (out_dim={y.shape[1]} != K={K_expected}).\")\n",
    "        return None\n",
    "    # Return floats; downstream estimator clamps to physical range\n",
    "    return np.clip(y.astype(float), 1.0, float(N_EMITTED_PER_TX))\n",
    "\n",
    "def predict_angles(X, spec, K_expected):\n",
    "    mdl, scl, ym, ys = spec[\"model\"], spec[\"scaler\"], spec[\"y_mean\"], spec[\"y_std\"]\n",
    "    Xs = scl.transform(X)\n",
    "    with torch.no_grad():\n",
    "        y_s = mdl(torch.tensor(Xs, dtype=torch.float32)).cpu().numpy()  # (N, 3*K_m)\n",
    "    y = y_s * ys + ym\n",
    "    if y.shape[1] % 3 != 0:\n",
    "        print(f\"[WARN] Angle model output dim {y.shape[1]} not divisible by 3; skipping.\")\n",
    "        return None\n",
    "    K_m = y.shape[1] // 3\n",
    "    if K_m != K_expected:\n",
    "        print(f\"[WARN] Skipping angle model (K_out={K_m} != K={K_expected}).\")\n",
    "        return None\n",
    "    # Convert to unit directions (N, K, 3)\n",
    "    y = y.reshape(y.shape[0], K_m, 3)\n",
    "    dirs = np.zeros_like(y)\n",
    "    for i in range(y.shape[0]):\n",
    "        for k in range(K_m):\n",
    "            dirs[i, k] = unit_vec(y[i, k])\n",
    "    return dirs  # (N, K, 3)\n",
    "\n",
    "size_preds = {}\n",
    "for name, spec in size_models.items():\n",
    "    pred = predict_sizes(X4K, spec, K_expected=K)\n",
    "    if pred is not None:\n",
    "        size_preds[name] = pred\n",
    "\n",
    "angle_preds = {}\n",
    "for name, spec in angle_models.items():\n",
    "    pred = predict_angles(X4K, spec, K_expected=K)\n",
    "    if pred is not None:\n",
    "        angle_preds[name] = pred\n",
    "\n",
    "print(\"Step 3 — Predictions obtained.\")\n",
    "\n",
    "# ====================== Step 4 — Evaluate predicted variants ======================\n",
    "results = []\n",
    "\n",
    "# SIZE-ONLY (use raw dirs via est_centers, predicted counts)\n",
    "for name_sz, y_counts in size_preds.items():\n",
    "    est, tru = [], []\n",
    "    skipped = 0\n",
    "    for j, (_, r) in enumerate(pairs.iterrows()):\n",
    "        T = np.asarray(truth_map[int(r[\"file_index\"])], dtype=float)  # (K,3)\n",
    "        E = []\n",
    "        for k in range(K):\n",
    "            tx, _, _ = estimate_tx_from_cluster_r0(\n",
    "                center_vec=r[\"est_centers\"][k],\n",
    "                n_received=float(y_counts[j, k]),  # positional index!\n",
    "                N_emitted=N_EMITTED_PER_TX, D=D, t=T_HORIZON,\n",
    "                r_r=R_R_FIXED, rx_center=np.array([0.,0.,0.])\n",
    "            )\n",
    "            E.append(tx)\n",
    "        E = np.asarray(E, dtype=float)  # (K,3)\n",
    "        if not (np.all(np.isfinite(E)) and np.all(np.isfinite(T))):\n",
    "            skipped += 1\n",
    "            continue\n",
    "        cost = cdist(E, T, metric=\"euclidean\")\n",
    "        r_ind, c_ind = linear_sum_assignment(cost)\n",
    "        est.extend(E[r_ind]); tru.extend(T[c_ind])\n",
    "    rmse = vector_rmse(est, tru)\n",
    "    mape = vector_mape(est, tru)\n",
    "    print(f\"Step 4 — SIZE-ONLY[{name_sz}] | RMSE: {rmse:.6f} | MAPE: {mape:.3f}% | matches: {len(est)} | skipped scenes: {skipped}\")\n",
    "    results.append(dict(variant=\"SIZE-ONLY\", model=name_sz, rmse=rmse, mape=mape, matches=len(est)))\n",
    "\n",
    "# ANGLE-ONLY (use predicted dirs, observed counts to set radii via estimate_tx_from_cluster_r0)\n",
    "for name_ang, dirs in angle_preds.items():\n",
    "    est, tru = [], []\n",
    "    skipped = 0\n",
    "\n",
    "    for j, (_, r) in enumerate(pairs.iterrows()):\n",
    "        T = np.asarray(truth_map[int(r[\"file_index\"])], dtype=float)  # (K,3)\n",
    "        if T.shape[0] != K or not np.all(np.isfinite(T)):\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        tx_estimates = []\n",
    "        ok = True\n",
    "\n",
    "        for k in range(K):\n",
    "            # direction for this cluster (ensure unit length)\n",
    "            dir_k = np.asarray(dirs[j][k], dtype=float)\n",
    "            n = np.linalg.norm(dir_k)\n",
    "            if not np.isfinite(n) or n < 1e-12:\n",
    "                ok = False\n",
    "                break\n",
    "            dir_k = dir_k / n\n",
    "\n",
    "            # observed count for this cluster\n",
    "            n_recv = float(r[\"est_sizes\"][k])\n",
    "\n",
    "            # estimate tx position along dir_k based on r0 inversion\n",
    "            tx_est, r0, F_used = estimate_tx_from_cluster_r0(\n",
    "                center_vec=dir_k,                 # just a direction; function normalizes anyway\n",
    "                n_received=n_recv,\n",
    "                N_emitted=N_EMITTED_PER_TX,\n",
    "                D=D,\n",
    "                t=T_HORIZON,\n",
    "                r_r=R_R_FIXED,\n",
    "                rx_center=np.array([0.0, 0.0, 0.0])  # receiver at origin\n",
    "            )\n",
    "\n",
    "            if not np.all(np.isfinite(tx_est)):\n",
    "                ok = False\n",
    "                break\n",
    "\n",
    "            tx_estimates.append(tx_est)\n",
    "\n",
    "        if not ok:\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        E = np.vstack(tx_estimates)  # (K,3)\n",
    "        cost = cdist(E, T, metric=\"euclidean\")\n",
    "        r_ind, c_ind = linear_sum_assignment(cost)\n",
    "        est.extend(E[r_ind]); tru.extend(T[c_ind])\n",
    "\n",
    "    rmse = vector_rmse(est, tru)\n",
    "    mape = vector_mape(est, tru)\n",
    "    print(f\"Step 4 — ANGLE-ONLY[{name_ang}] | RMSE: {rmse:.6f} | MAPE: {mape:.3f}% | matches: {len(est)} | skipped scenes: {skipped}\")\n",
    "    results.append(dict(variant=\"ANGLE-ONLY\", model=name_ang, rmse=rmse, mape=mape, matches=len(est)))\n",
    "\n",
    "# ANGLE+SIZE (use predicted dirs and predicted counts via r0 inversion)\n",
    "for name_ang, dirs in angle_preds.items():\n",
    "    for name_sz, y_counts in size_preds.items():\n",
    "        est, tru = [], []\n",
    "        skipped = 0\n",
    "\n",
    "        for j, (_, r) in enumerate(pairs.iterrows()):\n",
    "            T = np.asarray(truth_map[int(r[\"file_index\"])], dtype=float)  # (K,3)\n",
    "            if T.shape[0] != K or not np.all(np.isfinite(T)):\n",
    "                skipped += 1\n",
    "                continue\n",
    "\n",
    "            tx_estimates = []\n",
    "            ok = True\n",
    "\n",
    "            for k in range(K):\n",
    "                # direction for this cluster -> ensure unit vector\n",
    "                dir_k = np.asarray(dirs[j][k], dtype=float)\n",
    "                nrm = np.linalg.norm(dir_k)\n",
    "                if not np.isfinite(nrm) or nrm < 1e-12:\n",
    "                    ok = False\n",
    "                    break\n",
    "                dir_k = dir_k / nrm\n",
    "\n",
    "                # predicted count for this cluster (float; function will clamp)\n",
    "                n_recv = float(y_counts[j, k])\n",
    "\n",
    "                # estimate tx position along dir_k based on r0 inversion\n",
    "                tx_est, r0, F_used = estimate_tx_from_cluster_r0(\n",
    "                    center_vec=dir_k,                 # direction is enough; function normalizes again\n",
    "                    n_received=n_recv,\n",
    "                    N_emitted=N_EMITTED_PER_TX,\n",
    "                    D=D,\n",
    "                    t=T_HORIZON,\n",
    "                    r_r=R_R_FIXED,\n",
    "                    rx_center=np.array([0.0, 0.0, 0.0])  # receiver at origin\n",
    "                )\n",
    "\n",
    "                if not np.all(np.isfinite(tx_est)):\n",
    "                    ok = False\n",
    "                    break\n",
    "\n",
    "                tx_estimates.append(tx_est)\n",
    "\n",
    "            if not ok:\n",
    "                skipped += 1\n",
    "                continue\n",
    "\n",
    "            E = np.vstack(tx_estimates)  # (K,3)\n",
    "            cost = cdist(E, T, metric=\"euclidean\")\n",
    "            r_ind, c_ind = linear_sum_assignment(cost)\n",
    "            est.extend(E[r_ind]); tru.extend(T[c_ind])\n",
    "\n",
    "        rmse = vector_rmse(est, tru)\n",
    "        mape = vector_mape(est, tru)\n",
    "        print(f\"Step 4 — ANGLE+SIZE[{name_ang}×{name_sz}] | RMSE: {rmse:.6f} | MAPE: {mape:.3f}% | matches: {len(est)} | skipped scenes: {skipped}\")\n",
    "        results.append(dict(variant=\"ANGLE+SIZE\", model=f\"{name_ang} × {name_sz}\",\n",
    "                            rmse=rmse, mape=mape, matches=len(est)))\n",
    "\n",
    "# ====================== Summary & Save ======================\n",
    "summary = [dict(variant=\"RAW\", model=\"\", rmse=rmse_raw, mape=mape_raw, matches=len(raw_est))]\n",
    "summary.extend(results)\n",
    "res_df = pd.DataFrame(summary).sort_values([\"variant\",\"model\"]).reset_index(drop=True)\n",
    "print(\"\\n=== Summary (TEST only) ===\")\n",
    "print(res_df.to_string(index=False))\n",
    "\n",
    "out_csv = \"inversion_comparison_step_by_step_2Tx_TEST.csv\" \n",
    "res_df.to_csv(out_csv, index=False)\n",
    "print(f\"\\nSaved: {out_csv}\")\n",
    "\n",
    "# ====================== EXTRA: RAW results for OTHER methods (TEST only) ======================\n",
    "# This computes RAW (Step 1) for every other method present in DF_PATH and saves a separate CSV.\n",
    "df_all = pd.read_csv(DF_PATH).copy()\n",
    "df_all = df_all[df_all[\"file_index\"].isin(truth_map.keys())]\n",
    "\n",
    "# parse/clean needed columns\n",
    "df_all[\"est_center\"] = df_all[\"est_center\"].apply(to_vec3)\n",
    "df_all[\"est_size\"]   = pd.to_numeric(df_all[\"est_size\"], errors=\"coerce\")\n",
    "df_all[\"tx_index\"]   = pd.to_numeric(df_all[\"tx_index\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "selected_methods = [\n",
    "    \"Density-weighted centers (on KMeans partitions)\",\n",
    "    \"MCD-inlier density-weighted centers (on KMeans partitions)\",\n",
    "    \"Robust (MinCovDet) centers (on KMeans partitions)\",  \n",
    "]\n",
    "raw_rows = []\n",
    "for meth in selected_methods:\n",
    "    dm = df_all[df_all[\"method\"] == meth].dropna(subset=[\"tx_index\"]).copy()\n",
    "    dm[\"tx_index\"] = dm[\"tx_index\"].astype(int)\n",
    "\n",
    "    # ensure each file has all K clusters\n",
    "    gm = (dm.groupby([\"file_index\"], as_index=False)\n",
    "            .filter(has_all_k)\n",
    "            .sort_values([\"file_index\",\"tx_index\"])\n",
    "            .reset_index(drop=True))\n",
    "\n",
    "    # build pairs for this method\n",
    "    rows_m = []\n",
    "    for fid, s in gm.groupby(\"file_index\"):\n",
    "        s = s.sort_values(\"tx_index\")\n",
    "        if list(s[\"tx_index\"]) != list(range(K)):\n",
    "            continue\n",
    "        est_sizes = s[\"est_size\"].astype(float).to_numpy()\n",
    "        est_centers = np.vstack(s[\"est_center\"].tolist()).astype(float)\n",
    "        rows_m.append({\"file_index\": int(fid), \"est_sizes\": est_sizes, \"est_centers\": est_centers})\n",
    "    pairs_m = pd.DataFrame(rows_m)\n",
    "    if len(pairs_m) == 0:\n",
    "        print(f\"[RAW-OTHER] {meth}: no complete scenes.\")\n",
    "        continue\n",
    "\n",
    "    # TEST split filter\n",
    "    pairs_m = pairs_m[pairs_m[\"file_index\"].isin(test_files)].sort_values(\"file_index\").reset_index(drop=True)\n",
    "    if len(pairs_m) == 0:\n",
    "        print(f\"[RAW-OTHER] {meth}: no TEST scenes after split.\")\n",
    "        continue\n",
    "\n",
    "    # Step 1 RAW for this method\n",
    "    est_m, tru_m = [], []\n",
    "    skipped_m = 0\n",
    "    for _, rr in pairs_m.iterrows():\n",
    "        T = np.asarray(truth_map[int(rr[\"file_index\"])], dtype=float)  # (K,3)\n",
    "        E = []\n",
    "        for k in range(K):\n",
    "            c_vec = rr[\"est_centers\"][k]\n",
    "            n_recv = rr[\"est_sizes\"][k]\n",
    "            tx, _, _ = estimate_tx_from_cluster_r0(\n",
    "                center_vec=c_vec, n_received=float(n_recv),\n",
    "                N_emitted=N_EMITTED_PER_TX, D=D, t=T_HORIZON,\n",
    "                r_r=R_R_FIXED, rx_center=np.array([0.,0.,0.])\n",
    "            )\n",
    "            E.append(tx)\n",
    "        E = np.asarray(E, dtype=float)\n",
    "        if not (np.all(np.isfinite(E)) and np.all(np.isfinite(T)) and E.shape==(K,3) and T.shape==(K,3)):\n",
    "            skipped_m += 1\n",
    "            continue\n",
    "        cost = cdist(E, T, metric=\"euclidean\")\n",
    "        r_ind, c_ind = linear_sum_assignment(cost)\n",
    "        est_m.extend(E[r_ind]); tru_m.extend(T[c_ind])\n",
    "\n",
    "    rmse_m = vector_rmse(est_m, tru_m)\n",
    "    mape_m = vector_mape(est_m, tru_m)\n",
    "    print(f\"[RAW-OTHER] {meth} | RMSE: {rmse_m:.6f} | MAPE: {mape_m:.3f}% | matches: {len(est_m)} | skipped scenes: {skipped_m}\")\n",
    "    raw_rows.append(dict(method=meth, rmse=rmse_m, mape=mape_m, matches=len(est_m), skipped=skipped_m))\n",
    "\n",
    "raw_df = pd.DataFrame(raw_rows).sort_values([\"rmse\",\"method\"]).reset_index(drop=True)\n",
    "raw_out_csv = \"raw_results_other_methods_2Tx_TEST.csv\"\n",
    "raw_df.to_csv(raw_out_csv, index=False)\n",
    "print(f\"\\nSaved RAW other-methods results: {raw_out_csv}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1877b397-6da9-40b2-aea0-54b7ec173083",
   "metadata": {},
   "source": [
    "# Save Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "72e3f4c3-656d-45ec-9b64-9f1279253a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=2\n",
      "Test scenes: 2000\n",
      "Saved: angle_size_eval_test_2Tx.csv\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# ============================================================\n",
    "# Helpers\n",
    "# ============================================================\n",
    "def to_vec3(x):\n",
    "    if isinstance(x, list): return [float(x[0]), float(x[1]), float(x[2])]\n",
    "    if isinstance(x, str):  return list(map(float, ast.literal_eval(x)))\n",
    "    raise ValueError(\"Unexpected 3D vector format\")\n",
    "\n",
    "def to_length(v, L=5.0, eps=1e-12):\n",
    "    v = np.asarray(v, dtype=float)\n",
    "    n = np.linalg.norm(v)\n",
    "    if n < eps: return v.tolist()\n",
    "    return (v * (L / n)).tolist()\n",
    "\n",
    "def angle_between_vectors(v1, v2, eps=1e-12):\n",
    "    v1 = np.asarray(v1, dtype=float); v2 = np.asarray(v2, dtype=float)\n",
    "    n1 = np.linalg.norm(v1); n2 = np.linalg.norm(v2)\n",
    "    if n1 < eps or n2 < eps: return np.nan\n",
    "    cos_t = np.clip(np.dot(v1, v2) / (n1 * n2), -1.0, 1.0)\n",
    "    return float(np.degrees(np.arccos(cos_t)))\n",
    "\n",
    "def angles_matrix_deg(P, T):\n",
    "    \"\"\"Return KxK matrix of angular errors (degrees) between rows of P and T.\"\"\"\n",
    "    K = P.shape[0]\n",
    "    M = np.zeros((K, K), dtype=float)\n",
    "    for i in range(K):\n",
    "        for j in range(K):\n",
    "            M[i, j] = angle_between_vectors(P[i], T[j])\n",
    "    return M\n",
    "\n",
    "# ============================================================\n",
    "# Load base data and rebuild features (same preprocessing you used to train)\n",
    "# ============================================================\n",
    "DF_PATH = \"size_estimation.csv\"\n",
    "CONFIG_PATH = \"uniform_test/config.csv\"\n",
    "SPLIT_CSV = \"train_test_split_2Tx.csv\"   # created earlier\n",
    "\n",
    "df = pd.read_csv(DF_PATH)\n",
    "# keep same method filter you trained with\n",
    "df = df[df[\"method\"] == \"KMeans centers\"].copy()\n",
    "\n",
    "df[\"est_center\"] = df[\"est_center\"].apply(to_vec3)\n",
    "df[\"est_size\"]   = df[\"est_size\"].astype(float)\n",
    "df[\"true_size\"]  = df[\"true_size\"].astype(float)\n",
    "df[\"tx_index\"]   = df[\"tx_index\"].astype(int)\n",
    "\n",
    "# Infer K as before\n",
    "counts_per_file = df.groupby(\"file_index\")[\"tx_index\"].nunique()\n",
    "K_detected = int(counts_per_file.mode().iloc[0])\n",
    "if \"K\" in globals():\n",
    "    assert K == K_detected, f\"Inconsistent K: model K={K}, data K={K_detected}\"\n",
    "else:\n",
    "    K = K_detected\n",
    "print(f\"K={K}\")\n",
    "\n",
    "# Build per-file feature rows (same layout used for both models): X = [s0,c0x,c0y,c0z, s1,c1x,...]\n",
    "rows = []\n",
    "for fid, s in (df.groupby(\"file_index\")):\n",
    "    s = s.sort_values(\"tx_index\")\n",
    "    if set(s[\"tx_index\"].unique()) != set(range(K)):  # keep only complete scenes\n",
    "        continue\n",
    "    feat = []\n",
    "    true_sizes = []\n",
    "    est_centers_raw = []\n",
    "    for k in range(K):\n",
    "        feat.append(float(s.loc[s[\"tx_index\"] == k, \"est_size\"].values[0]))\n",
    "        c = list(map(float, s.loc[s[\"tx_index\"] == k, \"est_center\"].values[0]))\n",
    "        feat.extend(c)\n",
    "        est_centers_raw.append(c)\n",
    "        true_sizes.append(float(s.loc[s[\"tx_index\"] == k, \"true_size\"].values[0]))\n",
    "    rows.append({\n",
    "        \"file_index\": int(fid),\n",
    "        \"X\": feat,\n",
    "        \"true_sizes\": true_sizes,\n",
    "        \"raw_centers\": est_centers_raw,  # not used in output, but handy for diagnostics\n",
    "    })\n",
    "pairs = pd.DataFrame(rows).sort_values(\"file_index\").reset_index(drop=True)\n",
    "\n",
    "# Load ground-truth centers (angle targets) from config and scale each to length 5.0 (same as angle model)\n",
    "cfg = pd.read_csv(CONFIG_PATH)\n",
    "if \"file_index\" not in cfg.columns:\n",
    "    cfg = cfg.reset_index().rename(columns={\"index\":\"file_index\"})\n",
    "\n",
    "truth_map = {}\n",
    "for _, r in cfg.iterrows():\n",
    "    centers = r[\"tx_centers\"]\n",
    "    centers = ast.literal_eval(centers) if isinstance(centers, str) else centers\n",
    "    centers = [list(map(float, c)) for c in centers]\n",
    "    centers = [to_length(c, 5.0) for c in centers]\n",
    "    truth_map[int(r[\"file_index\"])] = centers\n",
    "\n",
    "# Add true angle targets (3K) to pairs\n",
    "y_angle_true = []\n",
    "for fid in pairs[\"file_index\"]:\n",
    "    centers = truth_map[int(fid)]\n",
    "    if len(centers) != K:\n",
    "        raise ValueError(f\"File {fid}: expected {K} centers in config, got {len(centers)}\")\n",
    "    y_angle_true.append(np.array(centers, dtype=float).reshape(-1))\n",
    "pairs[\"y_angle_true\"] = y_angle_true\n",
    "\n",
    "# ============================================================\n",
    "# Reuse the SAME test split\n",
    "# ============================================================\n",
    "split_df = pd.read_csv(SPLIT_CSV)\n",
    "test_files = set(split_df.loc[split_df[\"split\"] == \"test\", \"file_index\"].astype(int))\n",
    "\n",
    "pairs_test = pairs[pairs[\"file_index\"].isin(test_files)].copy().reset_index(drop=True)\n",
    "print(f\"Test scenes: {len(pairs_test)}\")\n",
    "\n",
    "# ============================================================\n",
    "# Predict with ANGLE model on test set\n",
    "#   Required globals: model, scaler_X, y_mean, y_std, K\n",
    "# ============================================================\n",
    "X_angle_test = np.array(pairs_test[\"X\"].to_list(), dtype=float)      # (N, 4K)\n",
    "Y_angle_true_flat = np.array(pairs_test[\"y_angle_true\"].to_list(), dtype=float)  # (N, 3K)\n",
    "\n",
    "# scale inputs with the angle-model scaler\n",
    "X_angle_test_s = scaler_X.transform(X_angle_test)\n",
    "\n",
    "import torch\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    Y_angle_pred_s = model(torch.from_numpy(X_angle_test_s.astype(np.float32))).cpu().numpy()\n",
    "Y_angle_pred = Y_angle_pred_s * y_std + y_mean   # (N, 3K)\n",
    "\n",
    "# reshape to (N, K, 3)\n",
    "Y_angle_pred = Y_angle_pred.reshape(-1, K, 3)\n",
    "Y_angle_true = Y_angle_true_flat.reshape(-1, K, 3)\n",
    "\n",
    "# ============================================================\n",
    "# Predict with SIZE model on the SAME test set\n",
    "#   Required globals: size, scaler_X_size, y_mean_size, y_std_size\n",
    "# ============================================================\n",
    "X_size_test  = X_angle_test                                   # same features\n",
    "true_sizes   = np.array(pairs_test[\"true_sizes\"].to_list())   # (N, K)\n",
    "\n",
    "X_size_test_s = scaler_X_size.transform(X_size_test)\n",
    "size.eval()\n",
    "with torch.no_grad():\n",
    "    y_size_pred_s = size(torch.from_numpy(X_size_test_s.astype(np.float32))).cpu().numpy()\n",
    "y_size_pred = y_size_pred_s * y_std_size + y_mean_size         # (N, K)\n",
    "\n",
    "# ============================================================\n",
    "# Build rows with Hungarian matching (by angle) PER SCENE\n",
    "# ============================================================\n",
    "out_rows = []\n",
    "for i, fid in enumerate(pairs_test[\"file_index\"].tolist()):\n",
    "    pred_centers = Y_angle_pred[i]    # (K,3)\n",
    "    true_centers = Y_angle_true[i]    # (K,3)\n",
    "\n",
    "    # Cost = angle error in degrees\n",
    "    cost = angles_matrix_deg(pred_centers, true_centers)\n",
    "    row_ind, col_ind = linear_sum_assignment(cost)  # match each pred (row) to a true (col)\n",
    "\n",
    "    # angles per matched pair (in pred order)\n",
    "    angles_deg = [cost[r, c] for r, c in zip(row_ind, col_ind)]\n",
    "    mean_angle = float(np.nanmean(angles_deg)) if len(angles_deg) else np.nan\n",
    "\n",
    "    # centers_est from ANGLE model (pred order 0..K-1)\n",
    "    centers_est_list = pred_centers.tolist()\n",
    "    # centers_true (ground-truth for ANGLE model) in native order 0..K-1\n",
    "    centers_true_list = true_centers.tolist()\n",
    "\n",
    "    # SIZE estimates (pred order 0..K-1)\n",
    "    cluster_sizes_est = y_size_pred[i].tolist()\n",
    "    # True sizes, matched to the pred order via col_ind (so each pred_k compares to true[col_ind[k]])\n",
    "    true_sizes_matched = true_sizes[i][col_ind].tolist()\n",
    "\n",
    "    out_rows.append({\n",
    "        \"file_index\": int(fid),\n",
    "        \"mean_angle_deg\": float(mean_angle),\n",
    "        \"angles_deg\": angles_deg,  # list\n",
    "        \"centers_est\": centers_est_list,\n",
    "        \"centers_true\": centers_true_list,\n",
    "        \"match_row_ind\": row_ind.tolist(),\n",
    "        \"match_col_ind\": col_ind.tolist(),\n",
    "        \"cluster_sizes\": cluster_sizes_est,\n",
    "        \"true_cluster_sizes_matched\": true_sizes_matched,\n",
    "    })\n",
    "\n",
    "# ============================================================\n",
    "# Save CSV\n",
    "# ============================================================\n",
    "result_df = pd.DataFrame(out_rows)\n",
    "\n",
    "# Serialize list-like columns as JSON strings for a clean 1-row-per-scene CSV\n",
    "list_cols = [\"angles_deg\", \"centers_est\", \"centers_true\", \"match_row_ind\", \"match_col_ind\",\n",
    "             \"cluster_sizes\", \"true_cluster_sizes_matched\"]\n",
    "for c in list_cols:\n",
    "    result_df[c] = result_df[c].apply(lambda x: json.dumps(x))\n",
    "\n",
    "OUT_CSV = \"angle_size_eval_test_2Tx.csv\"\n",
    "result_df.to_csv(OUT_CSV, index=False)\n",
    "print(f\"Saved: {OUT_CSV}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca87bb2-3993-4ebc-ba3e-dff163e113c5",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e71440a1-c156-498b-bd88-70e5625ef614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['size_scaler_2tx.joblib']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib, torch\n",
    "\n",
    "# angle\n",
    "torch.save({\n",
    "    \"K\": K,\n",
    "    \"model_state\": model.state_dict(),\n",
    "    \"y_mean\": y_mean,          # np array ok\n",
    "    \"y_std\":  y_std,\n",
    "}, \"angle_model_2tx.pt\")\n",
    "joblib.dump(scaler_X, \"angle_scaler_2tx.joblib\")\n",
    "\n",
    "# size\n",
    "torch.save({\n",
    "    \"K\": K,\n",
    "    \"model_state\": size.state_dict(),\n",
    "    \"y_mean\": y_mean_size,\n",
    "    \"y_std\":  y_std_size,\n",
    "}, \"size_model_2tx.pt\")\n",
    "joblib.dump(scaler_X_size, \"size_scaler_2tx.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cdf6dc-dcee-4710-a1d2-2e47e2fbe230",
   "metadata": {},
   "source": [
    "# Reload Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f287ad08-e8dc-47d7-bbda-ad83fc4416c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib, torch\n",
    "\n",
    "angle_state = torch.load(\"angle_model_2tx.pt\", map_location=\"cpu\", weights_only=True)\n",
    "scaler_X    = joblib.load(\"angle_scaler_2tx.joblib\")\n",
    "\n",
    "size_state  = torch.load(\"size_model_2tx.pt\", map_location=\"cpu\", weights_only=True)\n",
    "scaler_X_size = joblib.load(\"size_scaler_2tx.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d98633-2a9e-4655-a758-72707c65b70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model                        rmse      mape      \n",
    "\n",
    "K-MEANS                      1.213374 12.860955\n",
    "Density                      0.782876  7.355931    \n",
    "MinCovDet                    0.805381  7.899446    \n",
    "Dense-MinCovDet              0.753806  7.515043  \n",
    "ANGLE                        0.438117  4.997960\n",
    "SIZE                         1.178087 12.201972\n",
    "ANGLE+SIZE                   0.333272  3.709761"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc14a62a-05fd-4e96-9af2-f79ef3134179",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
